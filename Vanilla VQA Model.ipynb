{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10359140,"sourceType":"datasetVersion","datasetId":6415464}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==2.2.0 torchaudio torchsummary torchtext torchvision","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T08:56:47.772625Z","iopub.execute_input":"2025-01-04T08:56:47.772919Z","iopub.status.idle":"2025-01-04T08:59:20.200197Z","shell.execute_reply.started":"2025-01-04T08:56:47.772889Z","shell.execute_reply":"2025-01-04T08:59:20.199348Z"}},"outputs":[{"name":"stdout","text":"Collecting torch==2.2.0\n  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\nCollecting torchtext\n  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.0)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\nCollecting torchaudio\n  Downloading torchaudio-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading torchaudio-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading torchaudio-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading torchaudio-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\nINFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n  Downloading torchaudio-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading torchaudio-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.5)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\nINFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\nCollecting torchtext\n  Downloading torchtext-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n  Downloading torchtext-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (7.6 kB)\n  Downloading torchtext-0.17.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\nCollecting torchdata==0.7.1 (from torchtext)\n  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext) (2.2.3)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision\n  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nINFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0) (1.3.0)\nDownloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.2.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.17.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchdata, torchaudio, torchtext\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.1+cu121\n    Uninstalling torch-2.4.1+cu121:\n      Successfully uninstalled torch-2.4.1+cu121\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.1+cu121\n    Uninstalling torchvision-0.19.1+cu121:\n      Successfully uninstalled torchvision-0.19.1+cu121\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.4.1+cu121\n    Uninstalling torchaudio-2.4.1+cu121:\n      Successfully uninstalled torchaudio-2.4.1+cu121\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchaudio-2.2.0 torchdata-0.7.1 torchtext-0.17.0 torchvision-0.17.0 triton-2.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install numpy==1.24.3","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T08:59:47.328719Z","iopub.execute_input":"2025-01-04T08:59:47.329052Z","iopub.status.idle":"2025-01-04T08:59:55.485728Z","shell.execute_reply.started":"2025-01-04T08:59:47.329028Z","shell.execute_reply":"2025-01-04T08:59:55.484872Z"}},"outputs":[{"name":"stdout","text":"Collecting numpy==1.24.3\n  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nalbumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\nbayesian-optimization 2.0.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.24.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install spacy","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T08:59:57.105215Z","iopub.execute_input":"2025-01-04T08:59:57.105508Z","iopub.status.idle":"2025-01-04T09:00:00.314405Z","shell.execute_reply.started":"2025-01-04T08:59:57.105483Z","shell.execute_reply":"2025-01-04T09:00:00.313549Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.24.3)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T09:00:01.777228Z","iopub.execute_input":"2025-01-04T09:00:01.777529Z","iopub.status.idle":"2025-01-04T09:00:04.957714Z","shell.execute_reply.started":"2025-01-04T09:00:01.777509Z","shell.execute_reply":"2025-01-04T09:00:04.956866Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.6.85)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.24.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport random as rand\nimport os\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\nfrom torchtext.vocab import build_vocab_from_iterator\n\nimport spacy\nimport timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:00:06.328534Z","iopub.execute_input":"2025-01-04T09:00:06.328864Z","iopub.status.idle":"2025-01-04T09:00:17.583916Z","shell.execute_reply.started":"2025-01-04T09:00:06.328839Z","shell.execute_reply":"2025-01-04T09:00:17.583231Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def set_seed(seed):\n  rand.seed(seed)\n  np.random.seed(seed)\n  torch.cuda.manual_seed(seed)\n  torch.cuda.manual_seed_all(seed)\n  torch.backends.cudnn.deterministic = True\n  torch.backends.cudnn.benchmark = False\n\nseed = 59\nset_seed(59)\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:00:19.626359Z","iopub.execute_input":"2025-01-04T09:00:19.626638Z","iopub.status.idle":"2025-01-04T09:00:19.632912Z","shell.execute_reply.started":"2025-01-04T09:00:19.626619Z","shell.execute_reply":"2025-01-04T09:00:19.632208Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"data = open('/kaggle/input/dataset/vaq2.0.TrainImages.txt', 'r')\nlines = data.readlines()\nprint(lines[:5])  # Print the first 5 lines","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T09:00:48.367631Z","iopub.execute_input":"2025-01-04T09:00:48.367938Z","iopub.status.idle":"2025-01-04T09:00:48.375228Z","shell.execute_reply.started":"2025-01-04T09:00:48.367916Z","shell.execute_reply":"2025-01-04T09:00:48.374412Z"}},"outputs":[{"name":"stdout","text":"['COCO_val2014_000000393225.jpg#0\\tIs this a creamy soup ? no\\n', 'COCO_val2014_000000393243.jpg#0\\tIs this person wearing a tie ? no\\n', 'COCO_val2014_000000262197.jpg#0\\tIs this a hospital ? yes\\n', 'COCO_val2014_000000393277.jpg#0\\tAre there any tour buses ? no\\n', 'COCO_val2014_000000393277.jpg#1\\tIs this a one way street ? no\\n']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Load train data\ntrain_data = []\ntrain_path = '/kaggle/input/dataset/vaq2.0.TrainImages.txt'\nwith open(train_path, 'r') as f:\n    for i, line in enumerate(f.readlines()):\n        \n        full_sentence = line.split('\\t')\n        if (i < 3):\n            print(\"Full sentence: \", full_sentence)\n        \n        img_path = full_sentence[0][:-2]\n        if (i < 3):\n            print(\"Image Path: \", img_path)\n        \n        qa = full_sentence[1].split('?')\n        \n        question = qa[0]\n        if (i < 3):\n            print(\"Question: \", question)\n\n        # Error handling in case\n        if len(qa) == 3:\n            answer = qa[2]\n        else:\n            answer = qa[1]\n        \n        # Remove any trailing newline characters or extra spaces from the answer\n        answer = answer.strip()\n        \n        if (i < 3):\n            print(\"Answer: \", answer)\n            \n        if (i < 3):\n            print(\" \")\n            \n        data_sample = {\n            'Image Path': img_path,\n            'Question': question + '?',\n            'Answer': answer  # No trailing newline\n        }\n        train_data.append(data_sample)","metadata":{"trusted":true,"_kg_hide-input":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T09:00:55.871201Z","iopub.execute_input":"2025-01-04T09:00:55.871479Z","iopub.status.idle":"2025-01-04T09:00:55.897280Z","shell.execute_reply.started":"2025-01-04T09:00:55.871459Z","shell.execute_reply":"2025-01-04T09:00:55.896414Z"}},"outputs":[{"name":"stdout","text":"Full sentence:  ['COCO_val2014_000000393225.jpg#0', 'Is this a creamy soup ? no\\n']\nImage Path:  COCO_val2014_000000393225.jpg\nQuestion:  Is this a creamy soup \nAnswer:  no\n \nFull sentence:  ['COCO_val2014_000000393243.jpg#0', 'Is this person wearing a tie ? no\\n']\nImage Path:  COCO_val2014_000000393243.jpg\nQuestion:  Is this person wearing a tie \nAnswer:  no\n \nFull sentence:  ['COCO_val2014_000000262197.jpg#0', 'Is this a hospital ? yes\\n']\nImage Path:  COCO_val2014_000000262197.jpg\nQuestion:  Is this a hospital \nAnswer:  yes\n \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Load val data\nval_data = []\nval_path = '/kaggle/input/dataset/vaq2.0.DevImages.txt'\nwith open(val_path, 'r') as f:\n    for i, line in enumerate(f.readlines()):\n        \n        full_sentence = line.split('\\t')\n        if (i < 3):\n            print(\"Full sentence: \", full_sentence)\n        \n        img_path = full_sentence[0][:-2]\n        if (i < 3):\n            print(\"Image Path: \", img_path)\n        \n        qa = full_sentence[1].split('?')\n        \n        question = qa[0]\n        if (i < 3):\n            print(\"Question: \", question)\n\n        # Error handling in case\n        if len(qa) == 3:\n            answer = qa[2]\n        else:\n            answer = qa[1]\n        \n        # Remove any trailing newline characters or extra spaces from the answer\n        answer = answer.strip()\n        \n        if (i < 3):\n            print(\"Answer: \", answer)\n            \n        if (i < 3):\n            print(\" \")\n            \n        data_sample = {\n            'Image Path': img_path,\n            'Question': question + '?',\n            'Answer': answer  # No trailing newline\n        }\n        val_data.append(data_sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:00:57.950437Z","iopub.execute_input":"2025-01-04T09:00:57.950715Z","iopub.status.idle":"2025-01-04T09:00:57.973239Z","shell.execute_reply.started":"2025-01-04T09:00:57.950696Z","shell.execute_reply":"2025-01-04T09:00:57.972416Z"}},"outputs":[{"name":"stdout","text":"Full sentence:  ['COCO_val2014_000000262175.jpg#0', 'Is this a designer tie ? no\\n']\nImage Path:  COCO_val2014_000000262175.jpg\nQuestion:  Is this a designer tie \nAnswer:  no\n \nFull sentence:  ['COCO_val2014_000000393284.jpg#1', 'Is this man snowboarding ? yes\\n']\nImage Path:  COCO_val2014_000000393284.jpg\nQuestion:  Is this man snowboarding \nAnswer:  yes\n \nFull sentence:  ['COCO_val2014_000000000133.jpg#0', 'Is this a child room ? yes\\n']\nImage Path:  COCO_val2014_000000000133.jpg\nQuestion:  Is this a child room \nAnswer:  yes\n \n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Load train data\ntest_data = []\ntest_path = '/kaggle/input/dataset/vaq2.0.TestImages.txt'\nwith open(test_path, 'r') as f:\n    for i, line in enumerate(f.readlines()):\n        \n        full_sentence = line.split('\\t')\n        if (i < 3):\n            print(\"Full sentence: \", full_sentence)\n        \n        img_path = full_sentence[0][:-2]\n        if (i < 3):\n            print(\"Image Path: \", img_path)\n        \n        qa = full_sentence[1].split('?')\n        \n        question = qa[0]\n        if (i < 3):\n            print(\"Question: \", question)\n\n        # Error handling in case\n        if len(qa) == 3:\n            answer = qa[2]\n        else:\n            answer = qa[1]\n        \n        # Remove any trailing newline characters or extra spaces from the answer\n        answer = answer.strip()\n        \n        if (i < 3):\n            print(\"Answer: \", answer)\n            \n        if (i < 3):\n            print(\" \")\n            \n        data_sample = {\n            'Image Path': img_path,\n            'Question': question + '?',\n            'Answer': answer  # No trailing newline\n        }\n        test_data.append(data_sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:00.150180Z","iopub.execute_input":"2025-01-04T09:01:00.150458Z","iopub.status.idle":"2025-01-04T09:01:00.171696Z","shell.execute_reply.started":"2025-01-04T09:01:00.150437Z","shell.execute_reply":"2025-01-04T09:01:00.171060Z"}},"outputs":[{"name":"stdout","text":"Full sentence:  ['COCO_val2014_000000262162.jpg#0', 'Are there any boxes in the room ? no\\n']\nImage Path:  COCO_val2014_000000262162.jpg\nQuestion:  Are there any boxes in the room \nAnswer:  no\n \nFull sentence:  ['COCO_val2014_000000393277.jpg#0', 'Are there any any tour buses ? no\\n']\nImage Path:  COCO_val2014_000000393277.jpg\nQuestion:  Are there any any tour buses \nAnswer:  no\n \nFull sentence:  ['COCO_val2014_000000393284.jpg#2', 'Is this person flying ? no\\n']\nImage Path:  COCO_val2014_000000393284.jpg\nQuestion:  Is this person flying \nAnswer:  no\n \n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"eng = spacy.load('en_core_web_sm')\n\ndef get_tokens(data_iter):\n    \"\"\"\n    Input: data (dictionary)\n    \"\"\"\n    for sample in data_iter:\n        question = sample['Question']\n        yield[token.text for token \n              in eng.tokenizer(question)]\n\n# Build vocab from train set\nvocab = build_vocab_from_iterator(\n    get_tokens(train_data),\n    min_freq = 2, # Appears atleast 2 times\n    specials = ['<pad>', '<sos>', '<eos>', '<unk>'],\n    special_first = True\n)\nvocab.set_default_index (vocab['<unk>'])\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:02.700528Z","iopub.execute_input":"2025-01-04T09:01:02.700878Z","iopub.status.idle":"2025-01-04T09:01:03.765251Z","shell.execute_reply.started":"2025-01-04T09:01:02.700839Z","shell.execute_reply":"2025-01-04T09:01:03.764165Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Get all classes\nclasses = set([sample['Answer'] for sample in train_data])\n\nlabel2idx = {\n    cls_name: idx for idx, cls_name in enumerate(classes)\n}\nprint(label2idx)\nprint(\"Keys: \", label2idx.keys())\nprint(\"Values: \", label2idx.values())\n\nprint(\"\")\n\nidx2label = {\n    idx: cls_name for idx, cls_name in enumerate(classes)\n}\nprint(idx2label)\nprint(\"Keys: \", idx2label.keys())\nprint(\"Values: \", idx2label.values())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:05.004195Z","iopub.execute_input":"2025-01-04T09:01:05.004481Z","iopub.status.idle":"2025-01-04T09:01:05.013135Z","shell.execute_reply.started":"2025-01-04T09:01:05.004458Z","shell.execute_reply":"2025-01-04T09:01:05.012443Z"}},"outputs":[{"name":"stdout","text":"{'no': 0, 'yes': 1}\nKeys:  dict_keys(['no', 'yes'])\nValues:  dict_values([0, 1])\n\n{0: 'no', 1: 'yes'}\nKeys:  dict_keys([0, 1])\nValues:  dict_values(['no', 'yes'])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def tokenize(question, max_seq_len):\n    tokens = [token.text for token in eng.tokenizer(question)] # Tokenizes questions\n    seq = [vocab[token] for token in tokens]\n    if len(seq) < max_seq_len:\n        seq += [vocab['<pad>']] * (max_seq_len - len(seq)) # Add padding\n    else:\n        seq = seq[:max_seq_len] # Take until maxed length reached\n    \n    return seq\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:07.004396Z","iopub.execute_input":"2025-01-04T09:01:07.004701Z","iopub.status.idle":"2025-01-04T09:01:07.010488Z","shell.execute_reply.started":"2025-01-04T09:01:07.004676Z","shell.execute_reply":"2025-01-04T09:01:07.009599Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"class VQA_dataset(Dataset):\n    def __init__(self, data, label2idx, max_seq_len = 20, transform=None, img_dir = '/kaggle/input/dataset/val2014-resised'):\n        self.transform = transform\n        self.data = data\n        self.max_len = max_seq_len\n        self.img_dir = img_dir\n        self.label2idx = label2idx\n\n    # Returns: Number of samples\n    def __len__(self):\n        return len(self.data)\n        \n    # Returns: Transformed Image, tensorized Question & Label\n    def __getitem__(self, idx):\n        \n        # /kaggle/input/dataset/val2014-resised/Image Path\n        img_path = os.path.join(self.img_dir,\n                               self.data[idx]['Image Path'])\n        \n        # Open image and convert to RGB\n        img = Image.open(img_path).convert('RGB') \n        \n\n        if self.transform:\n            img = self.transform(img)\n            question = self.data[idx]['Question'] # Get question at index\n            question = tokenize(question, self.max_len) # Tokenizes question\n            question = torch.tensor(question, dtype=torch.long) # Converts to tensor as long type\n\n            label = self.data[idx]['Answer'] # Get answer/label\n            label = label2idx[label] # [0, 1]\n            label = torch.tensor(label, dtype = torch.long) # Converts to tensor as long type\n\n        return img, question, label\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:08.725903Z","iopub.execute_input":"2025-01-04T09:01:08.726193Z","iopub.status.idle":"2025-01-04T09:01:08.733170Z","shell.execute_reply.started":"2025-01-04T09:01:08.726171Z","shell.execute_reply":"2025-01-04T09:01:08.732460Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Dictionary that stores all transformation methods for train & val\ndata_transform = {\n    'train': transforms.Compose(\n        [\n            transforms.Resize(size = (224, 224)),\n            transforms.CenterCrop(size = 180),\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(brightness = 0.1,\n                                  contrast = 0.1,\n                                  saturation = 0.1),\n            transforms.RandomHorizontalFlip(),\n            transforms.GaussianBlur(3),\n            transforms.ToTensor(),\n            transforms.Normalize(\n                (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n            )\n        ]\n    ),\n\n    'val': transforms.Compose(\n        [\n        transforms.Resize(size = (224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n            )\n        ]\n    )\n}\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:11.149261Z","iopub.execute_input":"2025-01-04T09:01:11.149546Z","iopub.status.idle":"2025-01-04T09:01:11.155844Z","shell.execute_reply.started":"2025-01-04T09:01:11.149525Z","shell.execute_reply":"2025-01-04T09:01:11.155007Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_set = VQA_dataset(\n    train_data,\n    label2idx = label2idx,\n    transform = data_transform['train'] # Get all transformation for train\n)\n\nval_set = VQA_dataset(\n    val_data,\n    label2idx = label2idx,\n    transform = data_transform['val'] # Get all transformation for val\n)\n\ntest_set = VQA_dataset(\n    test_data,\n    label2idx = label2idx,\n    transform = data_transform['val'] # Same transformation as val\n)\n\nprint(train_set)\nprint(val_set)\nprint(test_set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:13.138543Z","iopub.execute_input":"2025-01-04T09:01:13.138856Z","iopub.status.idle":"2025-01-04T09:01:13.144570Z","shell.execute_reply.started":"2025-01-04T09:01:13.138832Z","shell.execute_reply":"2025-01-04T09:01:13.143716Z"}},"outputs":[{"name":"stdout","text":"<__main__.VQA_dataset object at 0x7c59bcd98a30>\n<__main__.VQA_dataset object at 0x7c59bcd98a00>\n<__main__.VQA_dataset object at 0x7c59bcd98e50>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"train_batch = 256\ntest_batch = 32\n\ntrain_loader = DataLoader(\n    train_set,\n    batch_size = train_batch,\n    shuffle = True\n)\n\nval_loader = DataLoader(\n    val_set,\n    batch_size = test_batch,\n    shuffle = False\n)\n\ntest_loader = DataLoader(\n    test_set,\n    batch_size = test_batch,\n    shuffle = False\n)\nprint(train_loader)\nprint(val_loader)\nprint(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:14.995263Z","iopub.execute_input":"2025-01-04T09:01:14.995536Z","iopub.status.idle":"2025-01-04T09:01:15.001826Z","shell.execute_reply.started":"2025-01-04T09:01:14.995517Z","shell.execute_reply":"2025-01-04T09:01:15.000970Z"}},"outputs":[{"name":"stdout","text":"<torch.utils.data.dataloader.DataLoader object at 0x7c59bbdb3070>\n<torch.utils.data.dataloader.DataLoader object at 0x7c59bbdb3be0>\n<torch.utils.data.dataloader.DataLoader object at 0x7c59bbdb1060>\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"class VQA_model(nn.Module):\n    def __init__(self, num_class, img_model_name, embed_dim,\n                num_layers = 2,\n                hidden_size = 256,\n                dropout_prob = 0.2):\n        super(VQA_model, self).__init__()\n\n        self.img_encoder = timm.create_model(\n            img_model_name,\n            pretrained = True,\n            num_classes = hidden_size\n        )\n        for param in self.img_encoder.parameters():\n            param.requires_grad = True\n\n\n        self.embed = nn.Embedding(len(vocab), embed_dim)\n\n        self.lstm1 = nn.LSTM(\n            input_size = embed_dim,\n            hidden_size = hidden_size,\n            num_layers = num_layers,\n            batch_first = True,\n            bidirectional = True,\n            dropout = dropout_prob\n        )\n        \n        \"\"\"\n            2 Layers LSTM => output 2 * Hidden Size\n            Concatenated encoded image => output Hidden Size\n            => Total nodes  = Hidden Size + 2 * Hidden Size = 3 * Hidden Size\n        \"\"\"\n        \n        self.fc1 = nn.Linear(hidden_size * 3, hidden_size)\n        self.dropout = nn.Dropout(dropout_prob)\n        self.gelu = nn.GELU()\n        self.fc2 = nn.Linear(hidden_size, num_class)\n\n    def forward(self, img, text):\n        img = self.img_encoder(img)\n\n        text = self.embed(text)\n        lstm_out, _ = self.lstm1(text)  # Get the tuple from LSTM\n        lstm_out = lstm_out[:, -1, :]   # Take the last hidden state from the output tensor\n\n\n        Concat = torch.cat((img, lstm_out), dim = 1) # Concat Encoded img & Encoded text\n        x = self.fc1(Concat)\n        x = self.gelu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return x\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:16.719426Z","iopub.execute_input":"2025-01-04T09:01:16.719711Z","iopub.status.idle":"2025-01-04T09:01:16.727696Z","shell.execute_reply.started":"2025-01-04T09:01:16.719690Z","shell.execute_reply":"2025-01-04T09:01:16.726757Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"num_class = len(classes)\nimg_model_name = 'resnet18'\nhidden_size = 256\nnum_layers = 2\nembed_dim = 128\ndropout_prob = 0.2\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = VQA_model(\n    num_class = num_class,\n    img_model_name = img_model_name,\n    embed_dim = embed_dim,\n    hidden_size = hidden_size,\n    num_layers = num_layers,\n    dropout_prob = dropout_prob\n).to(device)\n\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:18.939861Z","iopub.execute_input":"2025-01-04T09:01:18.940176Z","iopub.status.idle":"2025-01-04T09:01:19.823656Z","shell.execute_reply.started":"2025-01-04T09:01:18.940153Z","shell.execute_reply":"2025-01-04T09:01:19.822850Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6afc5d0eed3b463183388678caa07eb9"}},"metadata":{}},{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def eval(model, val_set, criterion, device):\n    model.eval()\n    corr = 0\n    total = 0\n    losses = []\n\n    with torch.no_grad():\n        for img, question, labels in val_set:\n            \n            img = img.to(device)\n            question = question.to(device)\n            labels = labels.to(device)\n\n            outputs = model(img, question)\n            loss = criterion(outputs, labels)\n\n            losses.append(loss.item())\n            _, pred = torch.max(outputs.data, 1) # Index of highest row\n            total += labels.size(0)\n            corr += (pred == labels).sum().item()\n    loss = sum(losses)/len(losses)\n    acc = corr/total\n\n    return loss, acc\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:21.095597Z","iopub.execute_input":"2025-01-04T09:01:21.095901Z","iopub.status.idle":"2025-01-04T09:01:21.102189Z","shell.execute_reply.started":"2025-01-04T09:01:21.095878Z","shell.execute_reply":"2025-01-04T09:01:21.101386Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import time\ndef train(model, train_data, val_data, criterion, optim, scheduler, device, epochs):\n    train_loss = []\n    val_loss = []\n    times = []\n    for i in range(epochs):\n        print(\"-\" * 59)\n        print(f'Starting Epoch {i + 1}...')\n        epoch_start_time = time.time()\n        batch_loss = []\n        model.train()\n        \n        for idx, (image, questions, labels) in enumerate(train_data):\n            image = image.to(device)\n            questions = questions.to(device)\n            labels = labels.to(device)\n\n            optim.zero_grad()\n\n            out = model(image, questions)\n            loss = criterion(out, labels)\n            loss.backward()\n            optim.step()\n            batch_loss.append(loss.item())\n            \n            print(f\"| Epoch: {i + 1} | {idx + 1}/{len(train_data)} Batches | Train Loss: {loss.item():.4f} |\")\n\n        train_loss1 = sum(batch_loss) / len(batch_loss)\n        train_loss.append(train_loss1)\n        val_loss1, val_acc = eval(\n            model, val_data, criterion, device\n        )\n        val_loss.append(val_loss1)\n        times.append(time.time() - epoch_start_time)\n        \n        print(f\"| Epoch: {i + 1}/{epochs:3d} | Train Loss: {train_loss1:.4f} | Val Loss: {val_loss1:.4f} | Val Accuracy: {val_acc:.2f} | Time: {(time.time() - epoch_start_time):.2f}s |\")\n        print(f\"Epoch {i + 1} was ran successfully\")\n        print(\"-\"*59)\n        scheduler.step()\n    return train_loss, val_loss\nprint(\"Done!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:11:25.869276Z","iopub.execute_input":"2025-01-04T09:11:25.869549Z","iopub.status.idle":"2025-01-04T09:11:25.876930Z","shell.execute_reply.started":"2025-01-04T09:11:25.869528Z","shell.execute_reply":"2025-01-04T09:11:25.876200Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"lr = 1e-3\nepochs = 50\n\nscheduler_step_size = epochs*0.8\ncriterion = nn.CrossEntropyLoss()\noptim = torch.optim.Adam(\n    model.parameters(),\n    lr = lr\n)\n\nscheduler = torch.optim.lr_scheduler.StepLR(\n    optim,\n    step_size = scheduler_step_size,\n    gamma = 0.1\n)\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T09:01:25.089847Z","iopub.execute_input":"2025-01-04T09:01:25.090154Z","iopub.status.idle":"2025-01-04T09:01:25.096608Z","shell.execute_reply.started":"2025-01-04T09:01:25.090130Z","shell.execute_reply":"2025-01-04T09:01:25.095764Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"train_loss, val_loss = train(model,\n                            train_loader,\n                            val_loader,\n                            criterion,\n                            optim,\n                            scheduler,\n                            device,\n                            epochs)\nprint(\"Done!\")","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T09:11:28.134566Z","iopub.execute_input":"2025-01-04T09:11:28.134891Z","iopub.status.idle":"2025-01-04T10:11:55.296273Z","shell.execute_reply.started":"2025-01-04T09:11:28.134865Z","shell.execute_reply":"2025-01-04T10:11:55.295428Z"}},"outputs":[{"name":"stdout","text":"Starting Epoch 1...\n| Epoch: 1 | 1/31 Batches | Train Loss: 0.2466 |\n| Epoch: 1 | 2/31 Batches | Train Loss: 0.3287 |\n| Epoch: 1 | 3/31 Batches | Train Loss: 0.3551 |\n| Epoch: 1 | 4/31 Batches | Train Loss: 0.3529 |\n| Epoch: 1 | 5/31 Batches | Train Loss: 0.3293 |\n| Epoch: 1 | 6/31 Batches | Train Loss: 0.2863 |\n| Epoch: 1 | 7/31 Batches | Train Loss: 0.2888 |\n| Epoch: 1 | 8/31 Batches | Train Loss: 0.2729 |\n| Epoch: 1 | 9/31 Batches | Train Loss: 0.3377 |\n| Epoch: 1 | 10/31 Batches | Train Loss: 0.3256 |\n| Epoch: 1 | 11/31 Batches | Train Loss: 0.3309 |\n| Epoch: 1 | 12/31 Batches | Train Loss: 0.3405 |\n| Epoch: 1 | 13/31 Batches | Train Loss: 0.3306 |\n| Epoch: 1 | 14/31 Batches | Train Loss: 0.3318 |\n| Epoch: 1 | 15/31 Batches | Train Loss: 0.3060 |\n| Epoch: 1 | 16/31 Batches | Train Loss: 0.3392 |\n| Epoch: 1 | 17/31 Batches | Train Loss: 0.3017 |\n| Epoch: 1 | 18/31 Batches | Train Loss: 0.4373 |\n| Epoch: 1 | 19/31 Batches | Train Loss: 0.3659 |\n| Epoch: 1 | 20/31 Batches | Train Loss: 0.3012 |\n| Epoch: 1 | 21/31 Batches | Train Loss: 0.3483 |\n| Epoch: 1 | 22/31 Batches | Train Loss: 0.3858 |\n| Epoch: 1 | 23/31 Batches | Train Loss: 0.3747 |\n| Epoch: 1 | 24/31 Batches | Train Loss: 0.3260 |\n| Epoch: 1 | 25/31 Batches | Train Loss: 0.3155 |\n| Epoch: 1 | 26/31 Batches | Train Loss: 0.3997 |\n| Epoch: 1 | 27/31 Batches | Train Loss: 0.3535 |\n| Epoch: 1 | 28/31 Batches | Train Loss: 0.3598 |\n| Epoch: 1 | 29/31 Batches | Train Loss: 0.3668 |\n| Epoch: 1 | 30/31 Batches | Train Loss: 0.3613 |\n| Epoch: 1 | 31/31 Batches | Train Loss: 0.3536 |\n-----------------------------------------------------------\n| Epoch: 1/ 50 | Train Loss: 0.3372 | Val Loss: 0.7421 | Val Accuracy: 0.59 | Time: 73.20s |\nEpoch 1 was ran successfully\nStarting Epoch 2...\n| Epoch: 2 | 1/31 Batches | Train Loss: 0.3199 |\n| Epoch: 2 | 2/31 Batches | Train Loss: 0.2244 |\n| Epoch: 2 | 3/31 Batches | Train Loss: 0.2606 |\n| Epoch: 2 | 4/31 Batches | Train Loss: 0.2442 |\n| Epoch: 2 | 5/31 Batches | Train Loss: 0.2237 |\n| Epoch: 2 | 6/31 Batches | Train Loss: 0.1907 |\n| Epoch: 2 | 7/31 Batches | Train Loss: 0.2453 |\n| Epoch: 2 | 8/31 Batches | Train Loss: 0.2290 |\n| Epoch: 2 | 9/31 Batches | Train Loss: 0.2997 |\n| Epoch: 2 | 10/31 Batches | Train Loss: 0.2694 |\n| Epoch: 2 | 11/31 Batches | Train Loss: 0.2323 |\n| Epoch: 2 | 12/31 Batches | Train Loss: 0.2915 |\n| Epoch: 2 | 13/31 Batches | Train Loss: 0.3294 |\n| Epoch: 2 | 14/31 Batches | Train Loss: 0.2296 |\n| Epoch: 2 | 15/31 Batches | Train Loss: 0.3079 |\n| Epoch: 2 | 16/31 Batches | Train Loss: 0.2155 |\n| Epoch: 2 | 17/31 Batches | Train Loss: 0.2585 |\n| Epoch: 2 | 18/31 Batches | Train Loss: 0.2212 |\n| Epoch: 2 | 19/31 Batches | Train Loss: 0.3389 |\n| Epoch: 2 | 20/31 Batches | Train Loss: 0.2570 |\n| Epoch: 2 | 21/31 Batches | Train Loss: 0.3009 |\n| Epoch: 2 | 22/31 Batches | Train Loss: 0.3513 |\n| Epoch: 2 | 23/31 Batches | Train Loss: 0.3515 |\n| Epoch: 2 | 24/31 Batches | Train Loss: 0.3050 |\n| Epoch: 2 | 25/31 Batches | Train Loss: 0.3366 |\n| Epoch: 2 | 26/31 Batches | Train Loss: 0.3267 |\n| Epoch: 2 | 27/31 Batches | Train Loss: 0.3277 |\n| Epoch: 2 | 28/31 Batches | Train Loss: 0.3551 |\n| Epoch: 2 | 29/31 Batches | Train Loss: 0.3028 |\n| Epoch: 2 | 30/31 Batches | Train Loss: 0.3223 |\n| Epoch: 2 | 31/31 Batches | Train Loss: 0.2819 |\n-----------------------------------------------------------\n| Epoch: 2/ 50 | Train Loss: 0.2823 | Val Loss: 0.7138 | Val Accuracy: 0.61 | Time: 71.42s |\nEpoch 2 was ran successfully\nStarting Epoch 3...\n| Epoch: 3 | 1/31 Batches | Train Loss: 0.2622 |\n| Epoch: 3 | 2/31 Batches | Train Loss: 0.2466 |\n| Epoch: 3 | 3/31 Batches | Train Loss: 0.2335 |\n| Epoch: 3 | 4/31 Batches | Train Loss: 0.2344 |\n| Epoch: 3 | 5/31 Batches | Train Loss: 0.2335 |\n| Epoch: 3 | 6/31 Batches | Train Loss: 0.2712 |\n| Epoch: 3 | 7/31 Batches | Train Loss: 0.1886 |\n| Epoch: 3 | 8/31 Batches | Train Loss: 0.2189 |\n| Epoch: 3 | 9/31 Batches | Train Loss: 0.2513 |\n| Epoch: 3 | 10/31 Batches | Train Loss: 0.2733 |\n| Epoch: 3 | 11/31 Batches | Train Loss: 0.2280 |\n| Epoch: 3 | 12/31 Batches | Train Loss: 0.2781 |\n| Epoch: 3 | 13/31 Batches | Train Loss: 0.2440 |\n| Epoch: 3 | 14/31 Batches | Train Loss: 0.2839 |\n| Epoch: 3 | 15/31 Batches | Train Loss: 0.2993 |\n| Epoch: 3 | 16/31 Batches | Train Loss: 0.2679 |\n| Epoch: 3 | 17/31 Batches | Train Loss: 0.2274 |\n| Epoch: 3 | 18/31 Batches | Train Loss: 0.3369 |\n| Epoch: 3 | 19/31 Batches | Train Loss: 0.2777 |\n| Epoch: 3 | 20/31 Batches | Train Loss: 0.2591 |\n| Epoch: 3 | 21/31 Batches | Train Loss: 0.2193 |\n| Epoch: 3 | 22/31 Batches | Train Loss: 0.2656 |\n| Epoch: 3 | 23/31 Batches | Train Loss: 0.2923 |\n| Epoch: 3 | 24/31 Batches | Train Loss: 0.2385 |\n| Epoch: 3 | 25/31 Batches | Train Loss: 0.2785 |\n| Epoch: 3 | 26/31 Batches | Train Loss: 0.3228 |\n| Epoch: 3 | 27/31 Batches | Train Loss: 0.2564 |\n| Epoch: 3 | 28/31 Batches | Train Loss: 0.2218 |\n| Epoch: 3 | 29/31 Batches | Train Loss: 0.3318 |\n| Epoch: 3 | 30/31 Batches | Train Loss: 0.3028 |\n| Epoch: 3 | 31/31 Batches | Train Loss: 0.2344 |\n-----------------------------------------------------------\n| Epoch: 3/ 50 | Train Loss: 0.2606 | Val Loss: 0.8373 | Val Accuracy: 0.61 | Time: 72.02s |\nEpoch 3 was ran successfully\nStarting Epoch 4...\n| Epoch: 4 | 1/31 Batches | Train Loss: 0.2183 |\n| Epoch: 4 | 2/31 Batches | Train Loss: 0.2579 |\n| Epoch: 4 | 3/31 Batches | Train Loss: 0.2446 |\n| Epoch: 4 | 4/31 Batches | Train Loss: 0.2007 |\n| Epoch: 4 | 5/31 Batches | Train Loss: 0.2469 |\n| Epoch: 4 | 6/31 Batches | Train Loss: 0.2178 |\n| Epoch: 4 | 7/31 Batches | Train Loss: 0.1864 |\n| Epoch: 4 | 8/31 Batches | Train Loss: 0.2019 |\n| Epoch: 4 | 9/31 Batches | Train Loss: 0.2498 |\n| Epoch: 4 | 10/31 Batches | Train Loss: 0.1892 |\n| Epoch: 4 | 11/31 Batches | Train Loss: 0.2529 |\n| Epoch: 4 | 12/31 Batches | Train Loss: 0.2429 |\n| Epoch: 4 | 13/31 Batches | Train Loss: 0.2490 |\n| Epoch: 4 | 14/31 Batches | Train Loss: 0.2154 |\n| Epoch: 4 | 15/31 Batches | Train Loss: 0.2772 |\n| Epoch: 4 | 16/31 Batches | Train Loss: 0.2111 |\n| Epoch: 4 | 17/31 Batches | Train Loss: 0.2401 |\n| Epoch: 4 | 18/31 Batches | Train Loss: 0.1893 |\n| Epoch: 4 | 19/31 Batches | Train Loss: 0.2231 |\n| Epoch: 4 | 20/31 Batches | Train Loss: 0.1967 |\n| Epoch: 4 | 21/31 Batches | Train Loss: 0.2758 |\n| Epoch: 4 | 22/31 Batches | Train Loss: 0.2188 |\n| Epoch: 4 | 23/31 Batches | Train Loss: 0.2162 |\n| Epoch: 4 | 24/31 Batches | Train Loss: 0.3033 |\n| Epoch: 4 | 25/31 Batches | Train Loss: 0.2542 |\n| Epoch: 4 | 26/31 Batches | Train Loss: 0.2338 |\n| Epoch: 4 | 27/31 Batches | Train Loss: 0.2871 |\n| Epoch: 4 | 28/31 Batches | Train Loss: 0.2096 |\n| Epoch: 4 | 29/31 Batches | Train Loss: 0.2199 |\n| Epoch: 4 | 30/31 Batches | Train Loss: 0.2070 |\n| Epoch: 4 | 31/31 Batches | Train Loss: 0.3244 |\n-----------------------------------------------------------\n| Epoch: 4/ 50 | Train Loss: 0.2342 | Val Loss: 0.8093 | Val Accuracy: 0.63 | Time: 71.27s |\nEpoch 4 was ran successfully\nStarting Epoch 5...\n| Epoch: 5 | 1/31 Batches | Train Loss: 0.1718 |\n| Epoch: 5 | 2/31 Batches | Train Loss: 0.1902 |\n| Epoch: 5 | 3/31 Batches | Train Loss: 0.1808 |\n| Epoch: 5 | 4/31 Batches | Train Loss: 0.2057 |\n| Epoch: 5 | 5/31 Batches | Train Loss: 0.1788 |\n| Epoch: 5 | 6/31 Batches | Train Loss: 0.1900 |\n| Epoch: 5 | 7/31 Batches | Train Loss: 0.2222 |\n| Epoch: 5 | 8/31 Batches | Train Loss: 0.2780 |\n| Epoch: 5 | 9/31 Batches | Train Loss: 0.1827 |\n| Epoch: 5 | 10/31 Batches | Train Loss: 0.2250 |\n| Epoch: 5 | 11/31 Batches | Train Loss: 0.1879 |\n| Epoch: 5 | 12/31 Batches | Train Loss: 0.1967 |\n| Epoch: 5 | 13/31 Batches | Train Loss: 0.1634 |\n| Epoch: 5 | 14/31 Batches | Train Loss: 0.2403 |\n| Epoch: 5 | 15/31 Batches | Train Loss: 0.1649 |\n| Epoch: 5 | 16/31 Batches | Train Loss: 0.2730 |\n| Epoch: 5 | 17/31 Batches | Train Loss: 0.1492 |\n| Epoch: 5 | 18/31 Batches | Train Loss: 0.2681 |\n| Epoch: 5 | 19/31 Batches | Train Loss: 0.2015 |\n| Epoch: 5 | 20/31 Batches | Train Loss: 0.1932 |\n| Epoch: 5 | 21/31 Batches | Train Loss: 0.2509 |\n| Epoch: 5 | 22/31 Batches | Train Loss: 0.1691 |\n| Epoch: 5 | 23/31 Batches | Train Loss: 0.1774 |\n| Epoch: 5 | 24/31 Batches | Train Loss: 0.2216 |\n| Epoch: 5 | 25/31 Batches | Train Loss: 0.3018 |\n| Epoch: 5 | 26/31 Batches | Train Loss: 0.2249 |\n| Epoch: 5 | 27/31 Batches | Train Loss: 0.2053 |\n| Epoch: 5 | 28/31 Batches | Train Loss: 0.2839 |\n| Epoch: 5 | 29/31 Batches | Train Loss: 0.2244 |\n| Epoch: 5 | 30/31 Batches | Train Loss: 0.2100 |\n| Epoch: 5 | 31/31 Batches | Train Loss: 0.2163 |\n-----------------------------------------------------------\n| Epoch: 5/ 50 | Train Loss: 0.2113 | Val Loss: 0.7850 | Val Accuracy: 0.63 | Time: 71.42s |\nEpoch 5 was ran successfully\nStarting Epoch 6...\n| Epoch: 6 | 1/31 Batches | Train Loss: 0.1909 |\n| Epoch: 6 | 2/31 Batches | Train Loss: 0.2013 |\n| Epoch: 6 | 3/31 Batches | Train Loss: 0.1402 |\n| Epoch: 6 | 4/31 Batches | Train Loss: 0.1503 |\n| Epoch: 6 | 5/31 Batches | Train Loss: 0.2034 |\n| Epoch: 6 | 6/31 Batches | Train Loss: 0.1514 |\n| Epoch: 6 | 7/31 Batches | Train Loss: 0.1964 |\n| Epoch: 6 | 8/31 Batches | Train Loss: 0.1642 |\n| Epoch: 6 | 9/31 Batches | Train Loss: 0.1882 |\n| Epoch: 6 | 10/31 Batches | Train Loss: 0.1993 |\n| Epoch: 6 | 11/31 Batches | Train Loss: 0.1976 |\n| Epoch: 6 | 12/31 Batches | Train Loss: 0.1980 |\n| Epoch: 6 | 13/31 Batches | Train Loss: 0.2060 |\n| Epoch: 6 | 14/31 Batches | Train Loss: 0.1962 |\n| Epoch: 6 | 15/31 Batches | Train Loss: 0.2209 |\n| Epoch: 6 | 16/31 Batches | Train Loss: 0.2267 |\n| Epoch: 6 | 17/31 Batches | Train Loss: 0.2089 |\n| Epoch: 6 | 18/31 Batches | Train Loss: 0.1944 |\n| Epoch: 6 | 19/31 Batches | Train Loss: 0.1877 |\n| Epoch: 6 | 20/31 Batches | Train Loss: 0.1514 |\n| Epoch: 6 | 21/31 Batches | Train Loss: 0.2779 |\n| Epoch: 6 | 22/31 Batches | Train Loss: 0.2378 |\n| Epoch: 6 | 23/31 Batches | Train Loss: 0.1839 |\n| Epoch: 6 | 24/31 Batches | Train Loss: 0.2426 |\n| Epoch: 6 | 25/31 Batches | Train Loss: 0.1725 |\n| Epoch: 6 | 26/31 Batches | Train Loss: 0.1798 |\n| Epoch: 6 | 27/31 Batches | Train Loss: 0.2039 |\n| Epoch: 6 | 28/31 Batches | Train Loss: 0.2135 |\n| Epoch: 6 | 29/31 Batches | Train Loss: 0.2106 |\n| Epoch: 6 | 30/31 Batches | Train Loss: 0.2033 |\n| Epoch: 6 | 31/31 Batches | Train Loss: 0.2504 |\n-----------------------------------------------------------\n| Epoch: 6/ 50 | Train Loss: 0.1984 | Val Loss: 0.9387 | Val Accuracy: 0.63 | Time: 72.73s |\nEpoch 6 was ran successfully\nStarting Epoch 7...\n| Epoch: 7 | 1/31 Batches | Train Loss: 0.1702 |\n| Epoch: 7 | 2/31 Batches | Train Loss: 0.1830 |\n| Epoch: 7 | 3/31 Batches | Train Loss: 0.2107 |\n| Epoch: 7 | 4/31 Batches | Train Loss: 0.1694 |\n| Epoch: 7 | 5/31 Batches | Train Loss: 0.2145 |\n| Epoch: 7 | 6/31 Batches | Train Loss: 0.1537 |\n| Epoch: 7 | 7/31 Batches | Train Loss: 0.1638 |\n| Epoch: 7 | 8/31 Batches | Train Loss: 0.1531 |\n| Epoch: 7 | 9/31 Batches | Train Loss: 0.1710 |\n| Epoch: 7 | 10/31 Batches | Train Loss: 0.1792 |\n| Epoch: 7 | 11/31 Batches | Train Loss: 0.1630 |\n| Epoch: 7 | 12/31 Batches | Train Loss: 0.1423 |\n| Epoch: 7 | 13/31 Batches | Train Loss: 0.1429 |\n| Epoch: 7 | 14/31 Batches | Train Loss: 0.1743 |\n| Epoch: 7 | 15/31 Batches | Train Loss: 0.1940 |\n| Epoch: 7 | 16/31 Batches | Train Loss: 0.1487 |\n| Epoch: 7 | 17/31 Batches | Train Loss: 0.2411 |\n| Epoch: 7 | 18/31 Batches | Train Loss: 0.2051 |\n| Epoch: 7 | 19/31 Batches | Train Loss: 0.1664 |\n| Epoch: 7 | 20/31 Batches | Train Loss: 0.1608 |\n| Epoch: 7 | 21/31 Batches | Train Loss: 0.2306 |\n| Epoch: 7 | 22/31 Batches | Train Loss: 0.1895 |\n| Epoch: 7 | 23/31 Batches | Train Loss: 0.1790 |\n| Epoch: 7 | 24/31 Batches | Train Loss: 0.2103 |\n| Epoch: 7 | 25/31 Batches | Train Loss: 0.1848 |\n| Epoch: 7 | 26/31 Batches | Train Loss: 0.1801 |\n| Epoch: 7 | 27/31 Batches | Train Loss: 0.2537 |\n| Epoch: 7 | 28/31 Batches | Train Loss: 0.1989 |\n| Epoch: 7 | 29/31 Batches | Train Loss: 0.1693 |\n| Epoch: 7 | 30/31 Batches | Train Loss: 0.2620 |\n| Epoch: 7 | 31/31 Batches | Train Loss: 0.2049 |\n-----------------------------------------------------------\n| Epoch: 7/ 50 | Train Loss: 0.1861 | Val Loss: 0.8460 | Val Accuracy: 0.63 | Time: 73.00s |\nEpoch 7 was ran successfully\nStarting Epoch 8...\n| Epoch: 8 | 1/31 Batches | Train Loss: 0.1322 |\n| Epoch: 8 | 2/31 Batches | Train Loss: 0.1511 |\n| Epoch: 8 | 3/31 Batches | Train Loss: 0.1270 |\n| Epoch: 8 | 4/31 Batches | Train Loss: 0.1032 |\n| Epoch: 8 | 5/31 Batches | Train Loss: 0.1559 |\n| Epoch: 8 | 6/31 Batches | Train Loss: 0.1931 |\n| Epoch: 8 | 7/31 Batches | Train Loss: 0.2141 |\n| Epoch: 8 | 8/31 Batches | Train Loss: 0.1928 |\n| Epoch: 8 | 9/31 Batches | Train Loss: 0.1172 |\n| Epoch: 8 | 10/31 Batches | Train Loss: 0.1457 |\n| Epoch: 8 | 11/31 Batches | Train Loss: 0.1382 |\n| Epoch: 8 | 12/31 Batches | Train Loss: 0.1801 |\n| Epoch: 8 | 13/31 Batches | Train Loss: 0.1223 |\n| Epoch: 8 | 14/31 Batches | Train Loss: 0.2222 |\n| Epoch: 8 | 15/31 Batches | Train Loss: 0.1284 |\n| Epoch: 8 | 16/31 Batches | Train Loss: 0.1994 |\n| Epoch: 8 | 17/31 Batches | Train Loss: 0.1489 |\n| Epoch: 8 | 18/31 Batches | Train Loss: 0.1846 |\n| Epoch: 8 | 19/31 Batches | Train Loss: 0.1737 |\n| Epoch: 8 | 20/31 Batches | Train Loss: 0.1637 |\n| Epoch: 8 | 21/31 Batches | Train Loss: 0.2085 |\n| Epoch: 8 | 22/31 Batches | Train Loss: 0.1603 |\n| Epoch: 8 | 23/31 Batches | Train Loss: 0.1541 |\n| Epoch: 8 | 24/31 Batches | Train Loss: 0.1736 |\n| Epoch: 8 | 25/31 Batches | Train Loss: 0.2266 |\n| Epoch: 8 | 26/31 Batches | Train Loss: 0.2214 |\n| Epoch: 8 | 27/31 Batches | Train Loss: 0.1716 |\n| Epoch: 8 | 28/31 Batches | Train Loss: 0.1767 |\n| Epoch: 8 | 29/31 Batches | Train Loss: 0.1535 |\n| Epoch: 8 | 30/31 Batches | Train Loss: 0.2347 |\n| Epoch: 8 | 31/31 Batches | Train Loss: 0.1682 |\n-----------------------------------------------------------\n| Epoch: 8/ 50 | Train Loss: 0.1691 | Val Loss: 1.0308 | Val Accuracy: 0.62 | Time: 71.71s |\nEpoch 8 was ran successfully\nStarting Epoch 9...\n| Epoch: 9 | 1/31 Batches | Train Loss: 0.1802 |\n| Epoch: 9 | 2/31 Batches | Train Loss: 0.1699 |\n| Epoch: 9 | 3/31 Batches | Train Loss: 0.1257 |\n| Epoch: 9 | 4/31 Batches | Train Loss: 0.1771 |\n| Epoch: 9 | 5/31 Batches | Train Loss: 0.1482 |\n| Epoch: 9 | 6/31 Batches | Train Loss: 0.1254 |\n| Epoch: 9 | 7/31 Batches | Train Loss: 0.1100 |\n| Epoch: 9 | 8/31 Batches | Train Loss: 0.1577 |\n| Epoch: 9 | 9/31 Batches | Train Loss: 0.1524 |\n| Epoch: 9 | 10/31 Batches | Train Loss: 0.1649 |\n| Epoch: 9 | 11/31 Batches | Train Loss: 0.1655 |\n| Epoch: 9 | 12/31 Batches | Train Loss: 0.1170 |\n| Epoch: 9 | 13/31 Batches | Train Loss: 0.1334 |\n| Epoch: 9 | 14/31 Batches | Train Loss: 0.1362 |\n| Epoch: 9 | 15/31 Batches | Train Loss: 0.2060 |\n| Epoch: 9 | 16/31 Batches | Train Loss: 0.1474 |\n| Epoch: 9 | 17/31 Batches | Train Loss: 0.1020 |\n| Epoch: 9 | 18/31 Batches | Train Loss: 0.1432 |\n| Epoch: 9 | 19/31 Batches | Train Loss: 0.2099 |\n| Epoch: 9 | 20/31 Batches | Train Loss: 0.1344 |\n| Epoch: 9 | 21/31 Batches | Train Loss: 0.1778 |\n| Epoch: 9 | 22/31 Batches | Train Loss: 0.1848 |\n| Epoch: 9 | 23/31 Batches | Train Loss: 0.1417 |\n| Epoch: 9 | 24/31 Batches | Train Loss: 0.1765 |\n| Epoch: 9 | 25/31 Batches | Train Loss: 0.1527 |\n| Epoch: 9 | 26/31 Batches | Train Loss: 0.1601 |\n| Epoch: 9 | 27/31 Batches | Train Loss: 0.1097 |\n| Epoch: 9 | 28/31 Batches | Train Loss: 0.1777 |\n| Epoch: 9 | 29/31 Batches | Train Loss: 0.2086 |\n| Epoch: 9 | 30/31 Batches | Train Loss: 0.1572 |\n| Epoch: 9 | 31/31 Batches | Train Loss: 0.1546 |\n-----------------------------------------------------------\n| Epoch: 9/ 50 | Train Loss: 0.1551 | Val Loss: 1.2149 | Val Accuracy: 0.62 | Time: 72.21s |\nEpoch 9 was ran successfully\nStarting Epoch 10...\n| Epoch: 10 | 1/31 Batches | Train Loss: 0.1430 |\n| Epoch: 10 | 2/31 Batches | Train Loss: 0.1220 |\n| Epoch: 10 | 3/31 Batches | Train Loss: 0.1437 |\n| Epoch: 10 | 4/31 Batches | Train Loss: 0.1114 |\n| Epoch: 10 | 5/31 Batches | Train Loss: 0.1804 |\n| Epoch: 10 | 6/31 Batches | Train Loss: 0.1788 |\n| Epoch: 10 | 7/31 Batches | Train Loss: 0.1529 |\n| Epoch: 10 | 8/31 Batches | Train Loss: 0.1646 |\n| Epoch: 10 | 9/31 Batches | Train Loss: 0.1506 |\n| Epoch: 10 | 10/31 Batches | Train Loss: 0.1100 |\n| Epoch: 10 | 11/31 Batches | Train Loss: 0.1382 |\n| Epoch: 10 | 12/31 Batches | Train Loss: 0.1171 |\n| Epoch: 10 | 13/31 Batches | Train Loss: 0.1377 |\n| Epoch: 10 | 14/31 Batches | Train Loss: 0.1453 |\n| Epoch: 10 | 15/31 Batches | Train Loss: 0.1711 |\n| Epoch: 10 | 16/31 Batches | Train Loss: 0.1290 |\n| Epoch: 10 | 17/31 Batches | Train Loss: 0.1840 |\n| Epoch: 10 | 18/31 Batches | Train Loss: 0.1582 |\n| Epoch: 10 | 19/31 Batches | Train Loss: 0.1467 |\n| Epoch: 10 | 20/31 Batches | Train Loss: 0.1533 |\n| Epoch: 10 | 21/31 Batches | Train Loss: 0.1310 |\n| Epoch: 10 | 22/31 Batches | Train Loss: 0.2205 |\n| Epoch: 10 | 23/31 Batches | Train Loss: 0.1804 |\n| Epoch: 10 | 24/31 Batches | Train Loss: 0.1875 |\n| Epoch: 10 | 25/31 Batches | Train Loss: 0.1942 |\n| Epoch: 10 | 26/31 Batches | Train Loss: 0.1596 |\n| Epoch: 10 | 27/31 Batches | Train Loss: 0.1849 |\n| Epoch: 10 | 28/31 Batches | Train Loss: 0.1451 |\n| Epoch: 10 | 29/31 Batches | Train Loss: 0.1725 |\n| Epoch: 10 | 30/31 Batches | Train Loss: 0.1408 |\n| Epoch: 10 | 31/31 Batches | Train Loss: 0.2223 |\n-----------------------------------------------------------\n| Epoch: 10/ 50 | Train Loss: 0.1573 | Val Loss: 1.2183 | Val Accuracy: 0.61 | Time: 73.19s |\nEpoch 10 was ran successfully\nStarting Epoch 11...\n| Epoch: 11 | 1/31 Batches | Train Loss: 0.1206 |\n| Epoch: 11 | 2/31 Batches | Train Loss: 0.1253 |\n| Epoch: 11 | 3/31 Batches | Train Loss: 0.1351 |\n| Epoch: 11 | 4/31 Batches | Train Loss: 0.1897 |\n| Epoch: 11 | 5/31 Batches | Train Loss: 0.1394 |\n| Epoch: 11 | 6/31 Batches | Train Loss: 0.1855 |\n| Epoch: 11 | 7/31 Batches | Train Loss: 0.1595 |\n| Epoch: 11 | 8/31 Batches | Train Loss: 0.1808 |\n| Epoch: 11 | 9/31 Batches | Train Loss: 0.1438 |\n| Epoch: 11 | 10/31 Batches | Train Loss: 0.1668 |\n| Epoch: 11 | 11/31 Batches | Train Loss: 0.2425 |\n| Epoch: 11 | 12/31 Batches | Train Loss: 0.1522 |\n| Epoch: 11 | 13/31 Batches | Train Loss: 0.1487 |\n| Epoch: 11 | 14/31 Batches | Train Loss: 0.2055 |\n| Epoch: 11 | 15/31 Batches | Train Loss: 0.1466 |\n| Epoch: 11 | 16/31 Batches | Train Loss: 0.1566 |\n| Epoch: 11 | 17/31 Batches | Train Loss: 0.1551 |\n| Epoch: 11 | 18/31 Batches | Train Loss: 0.1962 |\n| Epoch: 11 | 19/31 Batches | Train Loss: 0.1743 |\n| Epoch: 11 | 20/31 Batches | Train Loss: 0.1966 |\n| Epoch: 11 | 21/31 Batches | Train Loss: 0.1781 |\n| Epoch: 11 | 22/31 Batches | Train Loss: 0.1419 |\n| Epoch: 11 | 23/31 Batches | Train Loss: 0.1395 |\n| Epoch: 11 | 24/31 Batches | Train Loss: 0.1573 |\n| Epoch: 11 | 25/31 Batches | Train Loss: 0.1464 |\n| Epoch: 11 | 26/31 Batches | Train Loss: 0.2282 |\n| Epoch: 11 | 27/31 Batches | Train Loss: 0.1607 |\n| Epoch: 11 | 28/31 Batches | Train Loss: 0.2524 |\n| Epoch: 11 | 29/31 Batches | Train Loss: 0.1834 |\n| Epoch: 11 | 30/31 Batches | Train Loss: 0.1231 |\n| Epoch: 11 | 31/31 Batches | Train Loss: 0.2643 |\n-----------------------------------------------------------\n| Epoch: 11/ 50 | Train Loss: 0.1708 | Val Loss: 1.2776 | Val Accuracy: 0.59 | Time: 73.29s |\nEpoch 11 was ran successfully\nStarting Epoch 12...\n| Epoch: 12 | 1/31 Batches | Train Loss: 0.1752 |\n| Epoch: 12 | 2/31 Batches | Train Loss: 0.1246 |\n| Epoch: 12 | 3/31 Batches | Train Loss: 0.1751 |\n| Epoch: 12 | 4/31 Batches | Train Loss: 0.1753 |\n| Epoch: 12 | 5/31 Batches | Train Loss: 0.1759 |\n| Epoch: 12 | 6/31 Batches | Train Loss: 0.1746 |\n| Epoch: 12 | 7/31 Batches | Train Loss: 0.1516 |\n| Epoch: 12 | 8/31 Batches | Train Loss: 0.1464 |\n| Epoch: 12 | 9/31 Batches | Train Loss: 0.1762 |\n| Epoch: 12 | 10/31 Batches | Train Loss: 0.1892 |\n| Epoch: 12 | 11/31 Batches | Train Loss: 0.1413 |\n| Epoch: 12 | 12/31 Batches | Train Loss: 0.1994 |\n| Epoch: 12 | 13/31 Batches | Train Loss: 0.1394 |\n| Epoch: 12 | 14/31 Batches | Train Loss: 0.1392 |\n| Epoch: 12 | 15/31 Batches | Train Loss: 0.2079 |\n| Epoch: 12 | 16/31 Batches | Train Loss: 0.1612 |\n| Epoch: 12 | 17/31 Batches | Train Loss: 0.1345 |\n| Epoch: 12 | 18/31 Batches | Train Loss: 0.1657 |\n| Epoch: 12 | 19/31 Batches | Train Loss: 0.1762 |\n| Epoch: 12 | 20/31 Batches | Train Loss: 0.1125 |\n| Epoch: 12 | 21/31 Batches | Train Loss: 0.1483 |\n| Epoch: 12 | 22/31 Batches | Train Loss: 0.1783 |\n| Epoch: 12 | 23/31 Batches | Train Loss: 0.2345 |\n| Epoch: 12 | 24/31 Batches | Train Loss: 0.1767 |\n| Epoch: 12 | 25/31 Batches | Train Loss: 0.1568 |\n| Epoch: 12 | 26/31 Batches | Train Loss: 0.1848 |\n| Epoch: 12 | 27/31 Batches | Train Loss: 0.1717 |\n| Epoch: 12 | 28/31 Batches | Train Loss: 0.1407 |\n| Epoch: 12 | 29/31 Batches | Train Loss: 0.1899 |\n| Epoch: 12 | 30/31 Batches | Train Loss: 0.1882 |\n| Epoch: 12 | 31/31 Batches | Train Loss: 0.1829 |\n-----------------------------------------------------------\n| Epoch: 12/ 50 | Train Loss: 0.1676 | Val Loss: 1.1624 | Val Accuracy: 0.60 | Time: 73.11s |\nEpoch 12 was ran successfully\nStarting Epoch 13...\n| Epoch: 13 | 1/31 Batches | Train Loss: 0.1456 |\n| Epoch: 13 | 2/31 Batches | Train Loss: 0.1722 |\n| Epoch: 13 | 3/31 Batches | Train Loss: 0.1521 |\n| Epoch: 13 | 4/31 Batches | Train Loss: 0.1277 |\n| Epoch: 13 | 5/31 Batches | Train Loss: 0.1226 |\n| Epoch: 13 | 6/31 Batches | Train Loss: 0.1194 |\n| Epoch: 13 | 7/31 Batches | Train Loss: 0.1321 |\n| Epoch: 13 | 8/31 Batches | Train Loss: 0.1754 |\n| Epoch: 13 | 9/31 Batches | Train Loss: 0.1918 |\n| Epoch: 13 | 10/31 Batches | Train Loss: 0.0948 |\n| Epoch: 13 | 11/31 Batches | Train Loss: 0.1470 |\n| Epoch: 13 | 12/31 Batches | Train Loss: 0.1916 |\n| Epoch: 13 | 13/31 Batches | Train Loss: 0.1030 |\n| Epoch: 13 | 14/31 Batches | Train Loss: 0.1558 |\n| Epoch: 13 | 15/31 Batches | Train Loss: 0.1625 |\n| Epoch: 13 | 16/31 Batches | Train Loss: 0.1146 |\n| Epoch: 13 | 17/31 Batches | Train Loss: 0.1317 |\n| Epoch: 13 | 18/31 Batches | Train Loss: 0.1552 |\n| Epoch: 13 | 19/31 Batches | Train Loss: 0.1402 |\n| Epoch: 13 | 20/31 Batches | Train Loss: 0.1370 |\n| Epoch: 13 | 21/31 Batches | Train Loss: 0.1153 |\n| Epoch: 13 | 22/31 Batches | Train Loss: 0.1575 |\n| Epoch: 13 | 23/31 Batches | Train Loss: 0.2328 |\n| Epoch: 13 | 24/31 Batches | Train Loss: 0.1853 |\n| Epoch: 13 | 25/31 Batches | Train Loss: 0.1574 |\n| Epoch: 13 | 26/31 Batches | Train Loss: 0.1893 |\n| Epoch: 13 | 27/31 Batches | Train Loss: 0.1500 |\n| Epoch: 13 | 28/31 Batches | Train Loss: 0.1744 |\n| Epoch: 13 | 29/31 Batches | Train Loss: 0.1671 |\n| Epoch: 13 | 30/31 Batches | Train Loss: 0.1655 |\n| Epoch: 13 | 31/31 Batches | Train Loss: 0.1931 |\n-----------------------------------------------------------\n| Epoch: 13/ 50 | Train Loss: 0.1536 | Val Loss: 1.0104 | Val Accuracy: 0.61 | Time: 71.80s |\nEpoch 13 was ran successfully\nStarting Epoch 14...\n| Epoch: 14 | 1/31 Batches | Train Loss: 0.1242 |\n| Epoch: 14 | 2/31 Batches | Train Loss: 0.1589 |\n| Epoch: 14 | 3/31 Batches | Train Loss: 0.1458 |\n| Epoch: 14 | 4/31 Batches | Train Loss: 0.1240 |\n| Epoch: 14 | 5/31 Batches | Train Loss: 0.1202 |\n| Epoch: 14 | 6/31 Batches | Train Loss: 0.1933 |\n| Epoch: 14 | 7/31 Batches | Train Loss: 0.1349 |\n| Epoch: 14 | 8/31 Batches | Train Loss: 0.2002 |\n| Epoch: 14 | 9/31 Batches | Train Loss: 0.1918 |\n| Epoch: 14 | 10/31 Batches | Train Loss: 0.1651 |\n| Epoch: 14 | 11/31 Batches | Train Loss: 0.1251 |\n| Epoch: 14 | 12/31 Batches | Train Loss: 0.1325 |\n| Epoch: 14 | 13/31 Batches | Train Loss: 0.1283 |\n| Epoch: 14 | 14/31 Batches | Train Loss: 0.1259 |\n| Epoch: 14 | 15/31 Batches | Train Loss: 0.0876 |\n| Epoch: 14 | 16/31 Batches | Train Loss: 0.1197 |\n| Epoch: 14 | 17/31 Batches | Train Loss: 0.1668 |\n| Epoch: 14 | 18/31 Batches | Train Loss: 0.2169 |\n| Epoch: 14 | 19/31 Batches | Train Loss: 0.1603 |\n| Epoch: 14 | 20/31 Batches | Train Loss: 0.1100 |\n| Epoch: 14 | 21/31 Batches | Train Loss: 0.1654 |\n| Epoch: 14 | 22/31 Batches | Train Loss: 0.1122 |\n| Epoch: 14 | 23/31 Batches | Train Loss: 0.1716 |\n| Epoch: 14 | 24/31 Batches | Train Loss: 0.1550 |\n| Epoch: 14 | 25/31 Batches | Train Loss: 0.1540 |\n| Epoch: 14 | 26/31 Batches | Train Loss: 0.1532 |\n| Epoch: 14 | 27/31 Batches | Train Loss: 0.1420 |\n| Epoch: 14 | 28/31 Batches | Train Loss: 0.1784 |\n| Epoch: 14 | 29/31 Batches | Train Loss: 0.1589 |\n| Epoch: 14 | 30/31 Batches | Train Loss: 0.1929 |\n| Epoch: 14 | 31/31 Batches | Train Loss: 0.1365 |\n-----------------------------------------------------------\n| Epoch: 14/ 50 | Train Loss: 0.1501 | Val Loss: 1.0078 | Val Accuracy: 0.63 | Time: 72.40s |\nEpoch 14 was ran successfully\nStarting Epoch 15...\n| Epoch: 15 | 1/31 Batches | Train Loss: 0.1390 |\n| Epoch: 15 | 2/31 Batches | Train Loss: 0.1653 |\n| Epoch: 15 | 3/31 Batches | Train Loss: 0.1567 |\n| Epoch: 15 | 4/31 Batches | Train Loss: 0.1229 |\n| Epoch: 15 | 5/31 Batches | Train Loss: 0.0867 |\n| Epoch: 15 | 6/31 Batches | Train Loss: 0.1592 |\n| Epoch: 15 | 7/31 Batches | Train Loss: 0.1194 |\n| Epoch: 15 | 8/31 Batches | Train Loss: 0.1170 |\n| Epoch: 15 | 9/31 Batches | Train Loss: 0.1149 |\n| Epoch: 15 | 10/31 Batches | Train Loss: 0.1601 |\n| Epoch: 15 | 11/31 Batches | Train Loss: 0.1249 |\n| Epoch: 15 | 12/31 Batches | Train Loss: 0.1379 |\n| Epoch: 15 | 13/31 Batches | Train Loss: 0.1289 |\n| Epoch: 15 | 14/31 Batches | Train Loss: 0.1267 |\n| Epoch: 15 | 15/31 Batches | Train Loss: 0.1233 |\n| Epoch: 15 | 16/31 Batches | Train Loss: 0.1230 |\n| Epoch: 15 | 17/31 Batches | Train Loss: 0.1232 |\n| Epoch: 15 | 18/31 Batches | Train Loss: 0.1547 |\n| Epoch: 15 | 19/31 Batches | Train Loss: 0.1154 |\n| Epoch: 15 | 20/31 Batches | Train Loss: 0.1151 |\n| Epoch: 15 | 21/31 Batches | Train Loss: 0.1270 |\n| Epoch: 15 | 22/31 Batches | Train Loss: 0.1657 |\n| Epoch: 15 | 23/31 Batches | Train Loss: 0.1152 |\n| Epoch: 15 | 24/31 Batches | Train Loss: 0.1455 |\n| Epoch: 15 | 25/31 Batches | Train Loss: 0.0989 |\n| Epoch: 15 | 26/31 Batches | Train Loss: 0.1287 |\n| Epoch: 15 | 27/31 Batches | Train Loss: 0.1315 |\n| Epoch: 15 | 28/31 Batches | Train Loss: 0.1656 |\n| Epoch: 15 | 29/31 Batches | Train Loss: 0.1199 |\n| Epoch: 15 | 30/31 Batches | Train Loss: 0.1340 |\n| Epoch: 15 | 31/31 Batches | Train Loss: 0.1495 |\n-----------------------------------------------------------\n| Epoch: 15/ 50 | Train Loss: 0.1321 | Val Loss: 1.4605 | Val Accuracy: 0.61 | Time: 72.48s |\nEpoch 15 was ran successfully\nStarting Epoch 16...\n| Epoch: 16 | 1/31 Batches | Train Loss: 0.1313 |\n| Epoch: 16 | 2/31 Batches | Train Loss: 0.1200 |\n| Epoch: 16 | 3/31 Batches | Train Loss: 0.1209 |\n| Epoch: 16 | 4/31 Batches | Train Loss: 0.1531 |\n| Epoch: 16 | 5/31 Batches | Train Loss: 0.1097 |\n| Epoch: 16 | 6/31 Batches | Train Loss: 0.1037 |\n| Epoch: 16 | 7/31 Batches | Train Loss: 0.1274 |\n| Epoch: 16 | 8/31 Batches | Train Loss: 0.1652 |\n| Epoch: 16 | 9/31 Batches | Train Loss: 0.1275 |\n| Epoch: 16 | 10/31 Batches | Train Loss: 0.1482 |\n| Epoch: 16 | 11/31 Batches | Train Loss: 0.1817 |\n| Epoch: 16 | 12/31 Batches | Train Loss: 0.1222 |\n| Epoch: 16 | 13/31 Batches | Train Loss: 0.1391 |\n| Epoch: 16 | 14/31 Batches | Train Loss: 0.1737 |\n| Epoch: 16 | 15/31 Batches | Train Loss: 0.1321 |\n| Epoch: 16 | 16/31 Batches | Train Loss: 0.1235 |\n| Epoch: 16 | 17/31 Batches | Train Loss: 0.1177 |\n| Epoch: 16 | 18/31 Batches | Train Loss: 0.1638 |\n| Epoch: 16 | 19/31 Batches | Train Loss: 0.1453 |\n| Epoch: 16 | 20/31 Batches | Train Loss: 0.1431 |\n| Epoch: 16 | 21/31 Batches | Train Loss: 0.1363 |\n| Epoch: 16 | 22/31 Batches | Train Loss: 0.1337 |\n| Epoch: 16 | 23/31 Batches | Train Loss: 0.1987 |\n| Epoch: 16 | 24/31 Batches | Train Loss: 0.1530 |\n| Epoch: 16 | 25/31 Batches | Train Loss: 0.2076 |\n| Epoch: 16 | 26/31 Batches | Train Loss: 0.1675 |\n| Epoch: 16 | 27/31 Batches | Train Loss: 0.1245 |\n| Epoch: 16 | 28/31 Batches | Train Loss: 0.1598 |\n| Epoch: 16 | 29/31 Batches | Train Loss: 0.1336 |\n| Epoch: 16 | 30/31 Batches | Train Loss: 0.1281 |\n| Epoch: 16 | 31/31 Batches | Train Loss: 0.2109 |\n-----------------------------------------------------------\n| Epoch: 16/ 50 | Train Loss: 0.1453 | Val Loss: 1.2610 | Val Accuracy: 0.62 | Time: 72.46s |\nEpoch 16 was ran successfully\nStarting Epoch 17...\n| Epoch: 17 | 1/31 Batches | Train Loss: 0.1100 |\n| Epoch: 17 | 2/31 Batches | Train Loss: 0.1358 |\n| Epoch: 17 | 3/31 Batches | Train Loss: 0.1553 |\n| Epoch: 17 | 4/31 Batches | Train Loss: 0.1587 |\n| Epoch: 17 | 5/31 Batches | Train Loss: 0.1853 |\n| Epoch: 17 | 6/31 Batches | Train Loss: 0.1274 |\n| Epoch: 17 | 7/31 Batches | Train Loss: 0.1303 |\n| Epoch: 17 | 8/31 Batches | Train Loss: 0.1437 |\n| Epoch: 17 | 9/31 Batches | Train Loss: 0.1338 |\n| Epoch: 17 | 10/31 Batches | Train Loss: 0.1403 |\n| Epoch: 17 | 11/31 Batches | Train Loss: 0.1475 |\n| Epoch: 17 | 12/31 Batches | Train Loss: 0.1928 |\n| Epoch: 17 | 13/31 Batches | Train Loss: 0.1773 |\n| Epoch: 17 | 14/31 Batches | Train Loss: 0.1407 |\n| Epoch: 17 | 15/31 Batches | Train Loss: 0.1242 |\n| Epoch: 17 | 16/31 Batches | Train Loss: 0.3063 |\n| Epoch: 17 | 17/31 Batches | Train Loss: 0.1719 |\n| Epoch: 17 | 18/31 Batches | Train Loss: 0.1820 |\n| Epoch: 17 | 19/31 Batches | Train Loss: 0.1879 |\n| Epoch: 17 | 20/31 Batches | Train Loss: 0.1528 |\n| Epoch: 17 | 21/31 Batches | Train Loss: 0.1814 |\n| Epoch: 17 | 22/31 Batches | Train Loss: 0.1731 |\n| Epoch: 17 | 23/31 Batches | Train Loss: 0.1570 |\n| Epoch: 17 | 24/31 Batches | Train Loss: 0.1175 |\n| Epoch: 17 | 25/31 Batches | Train Loss: 0.2293 |\n| Epoch: 17 | 26/31 Batches | Train Loss: 0.1917 |\n| Epoch: 17 | 27/31 Batches | Train Loss: 0.1632 |\n| Epoch: 17 | 28/31 Batches | Train Loss: 0.1546 |\n| Epoch: 17 | 29/31 Batches | Train Loss: 0.1669 |\n| Epoch: 17 | 30/31 Batches | Train Loss: 0.1722 |\n| Epoch: 17 | 31/31 Batches | Train Loss: 0.1767 |\n-----------------------------------------------------------\n| Epoch: 17/ 50 | Train Loss: 0.1641 | Val Loss: 1.3828 | Val Accuracy: 0.62 | Time: 72.47s |\nEpoch 17 was ran successfully\nStarting Epoch 18...\n| Epoch: 18 | 1/31 Batches | Train Loss: 0.1832 |\n| Epoch: 18 | 2/31 Batches | Train Loss: 0.1514 |\n| Epoch: 18 | 3/31 Batches | Train Loss: 0.1290 |\n| Epoch: 18 | 4/31 Batches | Train Loss: 0.1143 |\n| Epoch: 18 | 5/31 Batches | Train Loss: 0.1212 |\n| Epoch: 18 | 6/31 Batches | Train Loss: 0.1113 |\n| Epoch: 18 | 7/31 Batches | Train Loss: 0.2083 |\n| Epoch: 18 | 8/31 Batches | Train Loss: 0.1596 |\n| Epoch: 18 | 9/31 Batches | Train Loss: 0.1135 |\n| Epoch: 18 | 10/31 Batches | Train Loss: 0.1712 |\n| Epoch: 18 | 11/31 Batches | Train Loss: 0.1307 |\n| Epoch: 18 | 12/31 Batches | Train Loss: 0.1271 |\n| Epoch: 18 | 13/31 Batches | Train Loss: 0.1764 |\n| Epoch: 18 | 14/31 Batches | Train Loss: 0.1403 |\n| Epoch: 18 | 15/31 Batches | Train Loss: 0.1864 |\n| Epoch: 18 | 16/31 Batches | Train Loss: 0.1417 |\n| Epoch: 18 | 17/31 Batches | Train Loss: 0.1226 |\n| Epoch: 18 | 18/31 Batches | Train Loss: 0.1408 |\n| Epoch: 18 | 19/31 Batches | Train Loss: 0.1115 |\n| Epoch: 18 | 20/31 Batches | Train Loss: 0.1957 |\n| Epoch: 18 | 21/31 Batches | Train Loss: 0.1082 |\n| Epoch: 18 | 22/31 Batches | Train Loss: 0.1315 |\n| Epoch: 18 | 23/31 Batches | Train Loss: 0.1455 |\n| Epoch: 18 | 24/31 Batches | Train Loss: 0.1648 |\n| Epoch: 18 | 25/31 Batches | Train Loss: 0.1597 |\n| Epoch: 18 | 26/31 Batches | Train Loss: 0.2013 |\n| Epoch: 18 | 27/31 Batches | Train Loss: 0.1157 |\n| Epoch: 18 | 28/31 Batches | Train Loss: 0.1542 |\n| Epoch: 18 | 29/31 Batches | Train Loss: 0.1809 |\n| Epoch: 18 | 30/31 Batches | Train Loss: 0.1954 |\n| Epoch: 18 | 31/31 Batches | Train Loss: 0.1487 |\n-----------------------------------------------------------\n| Epoch: 18/ 50 | Train Loss: 0.1497 | Val Loss: 1.0905 | Val Accuracy: 0.62 | Time: 72.19s |\nEpoch 18 was ran successfully\nStarting Epoch 19...\n| Epoch: 19 | 1/31 Batches | Train Loss: 0.1294 |\n| Epoch: 19 | 2/31 Batches | Train Loss: 0.0989 |\n| Epoch: 19 | 3/31 Batches | Train Loss: 0.1118 |\n| Epoch: 19 | 4/31 Batches | Train Loss: 0.1039 |\n| Epoch: 19 | 5/31 Batches | Train Loss: 0.1354 |\n| Epoch: 19 | 6/31 Batches | Train Loss: 0.1326 |\n| Epoch: 19 | 7/31 Batches | Train Loss: 0.1230 |\n| Epoch: 19 | 8/31 Batches | Train Loss: 0.1161 |\n| Epoch: 19 | 9/31 Batches | Train Loss: 0.0842 |\n| Epoch: 19 | 10/31 Batches | Train Loss: 0.1643 |\n| Epoch: 19 | 11/31 Batches | Train Loss: 0.1079 |\n| Epoch: 19 | 12/31 Batches | Train Loss: 0.1150 |\n| Epoch: 19 | 13/31 Batches | Train Loss: 0.1428 |\n| Epoch: 19 | 14/31 Batches | Train Loss: 0.1594 |\n| Epoch: 19 | 15/31 Batches | Train Loss: 0.1672 |\n| Epoch: 19 | 16/31 Batches | Train Loss: 0.1240 |\n| Epoch: 19 | 17/31 Batches | Train Loss: 0.1199 |\n| Epoch: 19 | 18/31 Batches | Train Loss: 0.1659 |\n| Epoch: 19 | 19/31 Batches | Train Loss: 0.1443 |\n| Epoch: 19 | 20/31 Batches | Train Loss: 0.1087 |\n| Epoch: 19 | 21/31 Batches | Train Loss: 0.1292 |\n| Epoch: 19 | 22/31 Batches | Train Loss: 0.1528 |\n| Epoch: 19 | 23/31 Batches | Train Loss: 0.1174 |\n| Epoch: 19 | 24/31 Batches | Train Loss: 0.1269 |\n| Epoch: 19 | 25/31 Batches | Train Loss: 0.1706 |\n| Epoch: 19 | 26/31 Batches | Train Loss: 0.1581 |\n| Epoch: 19 | 27/31 Batches | Train Loss: 0.1385 |\n| Epoch: 19 | 28/31 Batches | Train Loss: 0.1291 |\n| Epoch: 19 | 29/31 Batches | Train Loss: 0.1627 |\n| Epoch: 19 | 30/31 Batches | Train Loss: 0.1481 |\n| Epoch: 19 | 31/31 Batches | Train Loss: 0.2073 |\n-----------------------------------------------------------\n| Epoch: 19/ 50 | Train Loss: 0.1353 | Val Loss: 1.4316 | Val Accuracy: 0.64 | Time: 71.79s |\nEpoch 19 was ran successfully\nStarting Epoch 20...\n| Epoch: 20 | 1/31 Batches | Train Loss: 0.1082 |\n| Epoch: 20 | 2/31 Batches | Train Loss: 0.0854 |\n| Epoch: 20 | 3/31 Batches | Train Loss: 0.1074 |\n| Epoch: 20 | 4/31 Batches | Train Loss: 0.1499 |\n| Epoch: 20 | 5/31 Batches | Train Loss: 0.1342 |\n| Epoch: 20 | 6/31 Batches | Train Loss: 0.1025 |\n| Epoch: 20 | 7/31 Batches | Train Loss: 0.1302 |\n| Epoch: 20 | 8/31 Batches | Train Loss: 0.1510 |\n| Epoch: 20 | 9/31 Batches | Train Loss: 0.1448 |\n| Epoch: 20 | 10/31 Batches | Train Loss: 0.1484 |\n| Epoch: 20 | 11/31 Batches | Train Loss: 0.1370 |\n| Epoch: 20 | 12/31 Batches | Train Loss: 0.2020 |\n| Epoch: 20 | 13/31 Batches | Train Loss: 0.1308 |\n| Epoch: 20 | 14/31 Batches | Train Loss: 0.1608 |\n| Epoch: 20 | 15/31 Batches | Train Loss: 0.1378 |\n| Epoch: 20 | 16/31 Batches | Train Loss: 0.1438 |\n| Epoch: 20 | 17/31 Batches | Train Loss: 0.1800 |\n| Epoch: 20 | 18/31 Batches | Train Loss: 0.1648 |\n| Epoch: 20 | 19/31 Batches | Train Loss: 0.1492 |\n| Epoch: 20 | 20/31 Batches | Train Loss: 0.1596 |\n| Epoch: 20 | 21/31 Batches | Train Loss: 0.1758 |\n| Epoch: 20 | 22/31 Batches | Train Loss: 0.1751 |\n| Epoch: 20 | 23/31 Batches | Train Loss: 0.1653 |\n| Epoch: 20 | 24/31 Batches | Train Loss: 0.1703 |\n| Epoch: 20 | 25/31 Batches | Train Loss: 0.1680 |\n| Epoch: 20 | 26/31 Batches | Train Loss: 0.1454 |\n| Epoch: 20 | 27/31 Batches | Train Loss: 0.1676 |\n| Epoch: 20 | 28/31 Batches | Train Loss: 0.1659 |\n| Epoch: 20 | 29/31 Batches | Train Loss: 0.0985 |\n| Epoch: 20 | 30/31 Batches | Train Loss: 0.1551 |\n| Epoch: 20 | 31/31 Batches | Train Loss: 0.1477 |\n-----------------------------------------------------------\n| Epoch: 20/ 50 | Train Loss: 0.1472 | Val Loss: 1.2113 | Val Accuracy: 0.62 | Time: 72.45s |\nEpoch 20 was ran successfully\nStarting Epoch 21...\n| Epoch: 21 | 1/31 Batches | Train Loss: 0.1312 |\n| Epoch: 21 | 2/31 Batches | Train Loss: 0.1305 |\n| Epoch: 21 | 3/31 Batches | Train Loss: 0.1232 |\n| Epoch: 21 | 4/31 Batches | Train Loss: 0.1481 |\n| Epoch: 21 | 5/31 Batches | Train Loss: 0.1465 |\n| Epoch: 21 | 6/31 Batches | Train Loss: 0.1165 |\n| Epoch: 21 | 7/31 Batches | Train Loss: 0.1484 |\n| Epoch: 21 | 8/31 Batches | Train Loss: 0.1218 |\n| Epoch: 21 | 9/31 Batches | Train Loss: 0.1934 |\n| Epoch: 21 | 10/31 Batches | Train Loss: 0.1626 |\n| Epoch: 21 | 11/31 Batches | Train Loss: 0.1414 |\n| Epoch: 21 | 12/31 Batches | Train Loss: 0.1357 |\n| Epoch: 21 | 13/31 Batches | Train Loss: 0.1530 |\n| Epoch: 21 | 14/31 Batches | Train Loss: 0.1491 |\n| Epoch: 21 | 15/31 Batches | Train Loss: 0.1371 |\n| Epoch: 21 | 16/31 Batches | Train Loss: 0.1277 |\n| Epoch: 21 | 17/31 Batches | Train Loss: 0.1249 |\n| Epoch: 21 | 18/31 Batches | Train Loss: 0.1375 |\n| Epoch: 21 | 19/31 Batches | Train Loss: 0.1448 |\n| Epoch: 21 | 20/31 Batches | Train Loss: 0.1588 |\n| Epoch: 21 | 21/31 Batches | Train Loss: 0.1366 |\n| Epoch: 21 | 22/31 Batches | Train Loss: 0.1366 |\n| Epoch: 21 | 23/31 Batches | Train Loss: 0.1235 |\n| Epoch: 21 | 24/31 Batches | Train Loss: 0.1453 |\n| Epoch: 21 | 25/31 Batches | Train Loss: 0.1445 |\n| Epoch: 21 | 26/31 Batches | Train Loss: 0.0916 |\n| Epoch: 21 | 27/31 Batches | Train Loss: 0.1071 |\n| Epoch: 21 | 28/31 Batches | Train Loss: 0.1039 |\n| Epoch: 21 | 29/31 Batches | Train Loss: 0.1441 |\n| Epoch: 21 | 30/31 Batches | Train Loss: 0.1277 |\n| Epoch: 21 | 31/31 Batches | Train Loss: 0.2375 |\n-----------------------------------------------------------\n| Epoch: 21/ 50 | Train Loss: 0.1397 | Val Loss: 1.4076 | Val Accuracy: 0.62 | Time: 72.08s |\nEpoch 21 was ran successfully\nStarting Epoch 22...\n| Epoch: 22 | 1/31 Batches | Train Loss: 0.1075 |\n| Epoch: 22 | 2/31 Batches | Train Loss: 0.1641 |\n| Epoch: 22 | 3/31 Batches | Train Loss: 0.1245 |\n| Epoch: 22 | 4/31 Batches | Train Loss: 0.1121 |\n| Epoch: 22 | 5/31 Batches | Train Loss: 0.1340 |\n| Epoch: 22 | 6/31 Batches | Train Loss: 0.1020 |\n| Epoch: 22 | 7/31 Batches | Train Loss: 0.1336 |\n| Epoch: 22 | 8/31 Batches | Train Loss: 0.1447 |\n| Epoch: 22 | 9/31 Batches | Train Loss: 0.1266 |\n| Epoch: 22 | 10/31 Batches | Train Loss: 0.1360 |\n| Epoch: 22 | 11/31 Batches | Train Loss: 0.1353 |\n| Epoch: 22 | 12/31 Batches | Train Loss: 0.1140 |\n| Epoch: 22 | 13/31 Batches | Train Loss: 0.1156 |\n| Epoch: 22 | 14/31 Batches | Train Loss: 0.1187 |\n| Epoch: 22 | 15/31 Batches | Train Loss: 0.1122 |\n| Epoch: 22 | 16/31 Batches | Train Loss: 0.1981 |\n| Epoch: 22 | 17/31 Batches | Train Loss: 0.1249 |\n| Epoch: 22 | 18/31 Batches | Train Loss: 0.1506 |\n| Epoch: 22 | 19/31 Batches | Train Loss: 0.1132 |\n| Epoch: 22 | 20/31 Batches | Train Loss: 0.1378 |\n| Epoch: 22 | 21/31 Batches | Train Loss: 0.1247 |\n| Epoch: 22 | 22/31 Batches | Train Loss: 0.1411 |\n| Epoch: 22 | 23/31 Batches | Train Loss: 0.1336 |\n| Epoch: 22 | 24/31 Batches | Train Loss: 0.1208 |\n| Epoch: 22 | 25/31 Batches | Train Loss: 0.1188 |\n| Epoch: 22 | 26/31 Batches | Train Loss: 0.0915 |\n| Epoch: 22 | 27/31 Batches | Train Loss: 0.1360 |\n| Epoch: 22 | 28/31 Batches | Train Loss: 0.1591 |\n| Epoch: 22 | 29/31 Batches | Train Loss: 0.1055 |\n| Epoch: 22 | 30/31 Batches | Train Loss: 0.1460 |\n| Epoch: 22 | 31/31 Batches | Train Loss: 0.1406 |\n-----------------------------------------------------------\n| Epoch: 22/ 50 | Train Loss: 0.1298 | Val Loss: 1.4188 | Val Accuracy: 0.62 | Time: 72.29s |\nEpoch 22 was ran successfully\nStarting Epoch 23...\n| Epoch: 23 | 1/31 Batches | Train Loss: 0.1422 |\n| Epoch: 23 | 2/31 Batches | Train Loss: 0.1018 |\n| Epoch: 23 | 3/31 Batches | Train Loss: 0.0834 |\n| Epoch: 23 | 4/31 Batches | Train Loss: 0.1068 |\n| Epoch: 23 | 5/31 Batches | Train Loss: 0.1256 |\n| Epoch: 23 | 6/31 Batches | Train Loss: 0.1249 |\n| Epoch: 23 | 7/31 Batches | Train Loss: 0.1150 |\n| Epoch: 23 | 8/31 Batches | Train Loss: 0.0975 |\n| Epoch: 23 | 9/31 Batches | Train Loss: 0.1317 |\n| Epoch: 23 | 10/31 Batches | Train Loss: 0.1176 |\n| Epoch: 23 | 11/31 Batches | Train Loss: 0.1178 |\n| Epoch: 23 | 12/31 Batches | Train Loss: 0.1664 |\n| Epoch: 23 | 13/31 Batches | Train Loss: 0.1768 |\n| Epoch: 23 | 14/31 Batches | Train Loss: 0.1615 |\n| Epoch: 23 | 15/31 Batches | Train Loss: 0.1159 |\n| Epoch: 23 | 16/31 Batches | Train Loss: 0.1383 |\n| Epoch: 23 | 17/31 Batches | Train Loss: 0.1031 |\n| Epoch: 23 | 18/31 Batches | Train Loss: 0.0994 |\n| Epoch: 23 | 19/31 Batches | Train Loss: 0.0829 |\n| Epoch: 23 | 20/31 Batches | Train Loss: 0.1238 |\n| Epoch: 23 | 21/31 Batches | Train Loss: 0.1249 |\n| Epoch: 23 | 22/31 Batches | Train Loss: 0.1216 |\n| Epoch: 23 | 23/31 Batches | Train Loss: 0.1856 |\n| Epoch: 23 | 24/31 Batches | Train Loss: 0.1294 |\n| Epoch: 23 | 25/31 Batches | Train Loss: 0.1230 |\n| Epoch: 23 | 26/31 Batches | Train Loss: 0.1219 |\n| Epoch: 23 | 27/31 Batches | Train Loss: 0.0860 |\n| Epoch: 23 | 28/31 Batches | Train Loss: 0.1104 |\n| Epoch: 23 | 29/31 Batches | Train Loss: 0.1390 |\n| Epoch: 23 | 30/31 Batches | Train Loss: 0.0952 |\n| Epoch: 23 | 31/31 Batches | Train Loss: 0.1354 |\n-----------------------------------------------------------\n| Epoch: 23/ 50 | Train Loss: 0.1227 | Val Loss: 1.4495 | Val Accuracy: 0.61 | Time: 72.68s |\nEpoch 23 was ran successfully\nStarting Epoch 24...\n| Epoch: 24 | 1/31 Batches | Train Loss: 0.1215 |\n| Epoch: 24 | 2/31 Batches | Train Loss: 0.1039 |\n| Epoch: 24 | 3/31 Batches | Train Loss: 0.1167 |\n| Epoch: 24 | 4/31 Batches | Train Loss: 0.0956 |\n| Epoch: 24 | 5/31 Batches | Train Loss: 0.1053 |\n| Epoch: 24 | 6/31 Batches | Train Loss: 0.1269 |\n| Epoch: 24 | 7/31 Batches | Train Loss: 0.0896 |\n| Epoch: 24 | 8/31 Batches | Train Loss: 0.1014 |\n| Epoch: 24 | 9/31 Batches | Train Loss: 0.0905 |\n| Epoch: 24 | 10/31 Batches | Train Loss: 0.1494 |\n| Epoch: 24 | 11/31 Batches | Train Loss: 0.1042 |\n| Epoch: 24 | 12/31 Batches | Train Loss: 0.1734 |\n| Epoch: 24 | 13/31 Batches | Train Loss: 0.1275 |\n| Epoch: 24 | 14/31 Batches | Train Loss: 0.1355 |\n| Epoch: 24 | 15/31 Batches | Train Loss: 0.1232 |\n| Epoch: 24 | 16/31 Batches | Train Loss: 0.1253 |\n| Epoch: 24 | 17/31 Batches | Train Loss: 0.1764 |\n| Epoch: 24 | 18/31 Batches | Train Loss: 0.0822 |\n| Epoch: 24 | 19/31 Batches | Train Loss: 0.1047 |\n| Epoch: 24 | 20/31 Batches | Train Loss: 0.1285 |\n| Epoch: 24 | 21/31 Batches | Train Loss: 0.1129 |\n| Epoch: 24 | 22/31 Batches | Train Loss: 0.1253 |\n| Epoch: 24 | 23/31 Batches | Train Loss: 0.1213 |\n| Epoch: 24 | 24/31 Batches | Train Loss: 0.1259 |\n| Epoch: 24 | 25/31 Batches | Train Loss: 0.1312 |\n| Epoch: 24 | 26/31 Batches | Train Loss: 0.1315 |\n| Epoch: 24 | 27/31 Batches | Train Loss: 0.1378 |\n| Epoch: 24 | 28/31 Batches | Train Loss: 0.1748 |\n| Epoch: 24 | 29/31 Batches | Train Loss: 0.1149 |\n| Epoch: 24 | 30/31 Batches | Train Loss: 0.1331 |\n| Epoch: 24 | 31/31 Batches | Train Loss: 0.1238 |\n-----------------------------------------------------------\n| Epoch: 24/ 50 | Train Loss: 0.1230 | Val Loss: 1.3388 | Val Accuracy: 0.65 | Time: 72.42s |\nEpoch 24 was ran successfully\nStarting Epoch 25...\n| Epoch: 25 | 1/31 Batches | Train Loss: 0.1232 |\n| Epoch: 25 | 2/31 Batches | Train Loss: 0.1201 |\n| Epoch: 25 | 3/31 Batches | Train Loss: 0.1386 |\n| Epoch: 25 | 4/31 Batches | Train Loss: 0.0970 |\n| Epoch: 25 | 5/31 Batches | Train Loss: 0.1060 |\n| Epoch: 25 | 6/31 Batches | Train Loss: 0.1871 |\n| Epoch: 25 | 7/31 Batches | Train Loss: 0.0992 |\n| Epoch: 25 | 8/31 Batches | Train Loss: 0.1014 |\n| Epoch: 25 | 9/31 Batches | Train Loss: 0.1523 |\n| Epoch: 25 | 10/31 Batches | Train Loss: 0.1107 |\n| Epoch: 25 | 11/31 Batches | Train Loss: 0.1226 |\n| Epoch: 25 | 12/31 Batches | Train Loss: 0.1221 |\n| Epoch: 25 | 13/31 Batches | Train Loss: 0.1157 |\n| Epoch: 25 | 14/31 Batches | Train Loss: 0.0990 |\n| Epoch: 25 | 15/31 Batches | Train Loss: 0.0994 |\n| Epoch: 25 | 16/31 Batches | Train Loss: 0.1173 |\n| Epoch: 25 | 17/31 Batches | Train Loss: 0.1005 |\n| Epoch: 25 | 18/31 Batches | Train Loss: 0.1355 |\n| Epoch: 25 | 19/31 Batches | Train Loss: 0.1463 |\n| Epoch: 25 | 20/31 Batches | Train Loss: 0.1106 |\n| Epoch: 25 | 21/31 Batches | Train Loss: 0.1490 |\n| Epoch: 25 | 22/31 Batches | Train Loss: 0.0847 |\n| Epoch: 25 | 23/31 Batches | Train Loss: 0.1150 |\n| Epoch: 25 | 24/31 Batches | Train Loss: 0.1292 |\n| Epoch: 25 | 25/31 Batches | Train Loss: 0.1388 |\n| Epoch: 25 | 26/31 Batches | Train Loss: 0.1739 |\n| Epoch: 25 | 27/31 Batches | Train Loss: 0.1168 |\n| Epoch: 25 | 28/31 Batches | Train Loss: 0.1546 |\n| Epoch: 25 | 29/31 Batches | Train Loss: 0.1350 |\n| Epoch: 25 | 30/31 Batches | Train Loss: 0.1122 |\n| Epoch: 25 | 31/31 Batches | Train Loss: 0.1696 |\n-----------------------------------------------------------\n| Epoch: 25/ 50 | Train Loss: 0.1253 | Val Loss: 1.3630 | Val Accuracy: 0.64 | Time: 72.10s |\nEpoch 25 was ran successfully\nStarting Epoch 26...\n| Epoch: 26 | 1/31 Batches | Train Loss: 0.1323 |\n| Epoch: 26 | 2/31 Batches | Train Loss: 0.0999 |\n| Epoch: 26 | 3/31 Batches | Train Loss: 0.0947 |\n| Epoch: 26 | 4/31 Batches | Train Loss: 0.1458 |\n| Epoch: 26 | 5/31 Batches | Train Loss: 0.1897 |\n| Epoch: 26 | 6/31 Batches | Train Loss: 0.1091 |\n| Epoch: 26 | 7/31 Batches | Train Loss: 0.1414 |\n| Epoch: 26 | 8/31 Batches | Train Loss: 0.1767 |\n| Epoch: 26 | 9/31 Batches | Train Loss: 0.1034 |\n| Epoch: 26 | 10/31 Batches | Train Loss: 0.1422 |\n| Epoch: 26 | 11/31 Batches | Train Loss: 0.1316 |\n| Epoch: 26 | 12/31 Batches | Train Loss: 0.1197 |\n| Epoch: 26 | 13/31 Batches | Train Loss: 0.1751 |\n| Epoch: 26 | 14/31 Batches | Train Loss: 0.1656 |\n| Epoch: 26 | 15/31 Batches | Train Loss: 0.1118 |\n| Epoch: 26 | 16/31 Batches | Train Loss: 0.1053 |\n| Epoch: 26 | 17/31 Batches | Train Loss: 0.1106 |\n| Epoch: 26 | 18/31 Batches | Train Loss: 0.1176 |\n| Epoch: 26 | 19/31 Batches | Train Loss: 0.1277 |\n| Epoch: 26 | 20/31 Batches | Train Loss: 0.1420 |\n| Epoch: 26 | 21/31 Batches | Train Loss: 0.1679 |\n| Epoch: 26 | 22/31 Batches | Train Loss: 0.1265 |\n| Epoch: 26 | 23/31 Batches | Train Loss: 0.1227 |\n| Epoch: 26 | 24/31 Batches | Train Loss: 0.1369 |\n| Epoch: 26 | 25/31 Batches | Train Loss: 0.1130 |\n| Epoch: 26 | 26/31 Batches | Train Loss: 0.1450 |\n| Epoch: 26 | 27/31 Batches | Train Loss: 0.1140 |\n| Epoch: 26 | 28/31 Batches | Train Loss: 0.1432 |\n| Epoch: 26 | 29/31 Batches | Train Loss: 0.1145 |\n| Epoch: 26 | 30/31 Batches | Train Loss: 0.1350 |\n| Epoch: 26 | 31/31 Batches | Train Loss: 0.1233 |\n-----------------------------------------------------------\n| Epoch: 26/ 50 | Train Loss: 0.1317 | Val Loss: 1.4052 | Val Accuracy: 0.63 | Time: 72.09s |\nEpoch 26 was ran successfully\nStarting Epoch 27...\n| Epoch: 27 | 1/31 Batches | Train Loss: 0.1063 |\n| Epoch: 27 | 2/31 Batches | Train Loss: 0.1592 |\n| Epoch: 27 | 3/31 Batches | Train Loss: 0.1194 |\n| Epoch: 27 | 4/31 Batches | Train Loss: 0.1350 |\n| Epoch: 27 | 5/31 Batches | Train Loss: 0.0813 |\n| Epoch: 27 | 6/31 Batches | Train Loss: 0.1447 |\n| Epoch: 27 | 7/31 Batches | Train Loss: 0.1369 |\n| Epoch: 27 | 8/31 Batches | Train Loss: 0.1144 |\n| Epoch: 27 | 9/31 Batches | Train Loss: 0.1312 |\n| Epoch: 27 | 10/31 Batches | Train Loss: 0.1548 |\n| Epoch: 27 | 11/31 Batches | Train Loss: 0.1040 |\n| Epoch: 27 | 12/31 Batches | Train Loss: 0.1238 |\n| Epoch: 27 | 13/31 Batches | Train Loss: 0.1098 |\n| Epoch: 27 | 14/31 Batches | Train Loss: 0.1094 |\n| Epoch: 27 | 15/31 Batches | Train Loss: 0.1599 |\n| Epoch: 27 | 16/31 Batches | Train Loss: 0.1357 |\n| Epoch: 27 | 17/31 Batches | Train Loss: 0.1106 |\n| Epoch: 27 | 18/31 Batches | Train Loss: 0.1031 |\n| Epoch: 27 | 19/31 Batches | Train Loss: 0.1696 |\n| Epoch: 27 | 20/31 Batches | Train Loss: 0.1492 |\n| Epoch: 27 | 21/31 Batches | Train Loss: 0.1410 |\n| Epoch: 27 | 22/31 Batches | Train Loss: 0.1776 |\n| Epoch: 27 | 23/31 Batches | Train Loss: 0.1387 |\n| Epoch: 27 | 24/31 Batches | Train Loss: 0.1088 |\n| Epoch: 27 | 25/31 Batches | Train Loss: 0.1308 |\n| Epoch: 27 | 26/31 Batches | Train Loss: 0.1560 |\n| Epoch: 27 | 27/31 Batches | Train Loss: 0.1669 |\n| Epoch: 27 | 28/31 Batches | Train Loss: 0.1721 |\n| Epoch: 27 | 29/31 Batches | Train Loss: 0.1365 |\n| Epoch: 27 | 30/31 Batches | Train Loss: 0.1556 |\n| Epoch: 27 | 31/31 Batches | Train Loss: 0.1256 |\n-----------------------------------------------------------\n| Epoch: 27/ 50 | Train Loss: 0.1344 | Val Loss: 1.1448 | Val Accuracy: 0.64 | Time: 72.11s |\nEpoch 27 was ran successfully\nStarting Epoch 28...\n| Epoch: 28 | 1/31 Batches | Train Loss: 0.1272 |\n| Epoch: 28 | 2/31 Batches | Train Loss: 0.1060 |\n| Epoch: 28 | 3/31 Batches | Train Loss: 0.0987 |\n| Epoch: 28 | 4/31 Batches | Train Loss: 0.1124 |\n| Epoch: 28 | 5/31 Batches | Train Loss: 0.1354 |\n| Epoch: 28 | 6/31 Batches | Train Loss: 0.1787 |\n| Epoch: 28 | 7/31 Batches | Train Loss: 0.1024 |\n| Epoch: 28 | 8/31 Batches | Train Loss: 0.0933 |\n| Epoch: 28 | 9/31 Batches | Train Loss: 0.1312 |\n| Epoch: 28 | 10/31 Batches | Train Loss: 0.1360 |\n| Epoch: 28 | 11/31 Batches | Train Loss: 0.1474 |\n| Epoch: 28 | 12/31 Batches | Train Loss: 0.1095 |\n| Epoch: 28 | 13/31 Batches | Train Loss: 0.1405 |\n| Epoch: 28 | 14/31 Batches | Train Loss: 0.1257 |\n| Epoch: 28 | 15/31 Batches | Train Loss: 0.1097 |\n| Epoch: 28 | 16/31 Batches | Train Loss: 0.1072 |\n| Epoch: 28 | 17/31 Batches | Train Loss: 0.1028 |\n| Epoch: 28 | 18/31 Batches | Train Loss: 0.0894 |\n| Epoch: 28 | 19/31 Batches | Train Loss: 0.1561 |\n| Epoch: 28 | 20/31 Batches | Train Loss: 0.1160 |\n| Epoch: 28 | 21/31 Batches | Train Loss: 0.1378 |\n| Epoch: 28 | 22/31 Batches | Train Loss: 0.1356 |\n| Epoch: 28 | 23/31 Batches | Train Loss: 0.1276 |\n| Epoch: 28 | 24/31 Batches | Train Loss: 0.0980 |\n| Epoch: 28 | 25/31 Batches | Train Loss: 0.1090 |\n| Epoch: 28 | 26/31 Batches | Train Loss: 0.1350 |\n| Epoch: 28 | 27/31 Batches | Train Loss: 0.1070 |\n| Epoch: 28 | 28/31 Batches | Train Loss: 0.1185 |\n| Epoch: 28 | 29/31 Batches | Train Loss: 0.1121 |\n| Epoch: 28 | 30/31 Batches | Train Loss: 0.1495 |\n| Epoch: 28 | 31/31 Batches | Train Loss: 0.1233 |\n-----------------------------------------------------------\n| Epoch: 28/ 50 | Train Loss: 0.1219 | Val Loss: 1.3995 | Val Accuracy: 0.64 | Time: 72.25s |\nEpoch 28 was ran successfully\nStarting Epoch 29...\n| Epoch: 29 | 1/31 Batches | Train Loss: 0.1056 |\n| Epoch: 29 | 2/31 Batches | Train Loss: 0.1545 |\n| Epoch: 29 | 3/31 Batches | Train Loss: 0.1011 |\n| Epoch: 29 | 4/31 Batches | Train Loss: 0.1098 |\n| Epoch: 29 | 5/31 Batches | Train Loss: 0.0807 |\n| Epoch: 29 | 6/31 Batches | Train Loss: 0.0886 |\n| Epoch: 29 | 7/31 Batches | Train Loss: 0.1062 |\n| Epoch: 29 | 8/31 Batches | Train Loss: 0.1035 |\n| Epoch: 29 | 9/31 Batches | Train Loss: 0.1076 |\n| Epoch: 29 | 10/31 Batches | Train Loss: 0.0957 |\n| Epoch: 29 | 11/31 Batches | Train Loss: 0.1196 |\n| Epoch: 29 | 12/31 Batches | Train Loss: 0.0895 |\n| Epoch: 29 | 13/31 Batches | Train Loss: 0.0916 |\n| Epoch: 29 | 14/31 Batches | Train Loss: 0.1123 |\n| Epoch: 29 | 15/31 Batches | Train Loss: 0.1520 |\n| Epoch: 29 | 16/31 Batches | Train Loss: 0.1450 |\n| Epoch: 29 | 17/31 Batches | Train Loss: 0.1104 |\n| Epoch: 29 | 18/31 Batches | Train Loss: 0.1561 |\n| Epoch: 29 | 19/31 Batches | Train Loss: 0.1125 |\n| Epoch: 29 | 20/31 Batches | Train Loss: 0.1069 |\n| Epoch: 29 | 21/31 Batches | Train Loss: 0.1242 |\n| Epoch: 29 | 22/31 Batches | Train Loss: 0.1440 |\n| Epoch: 29 | 23/31 Batches | Train Loss: 0.1725 |\n| Epoch: 29 | 24/31 Batches | Train Loss: 0.1208 |\n| Epoch: 29 | 25/31 Batches | Train Loss: 0.1077 |\n| Epoch: 29 | 26/31 Batches | Train Loss: 0.1343 |\n| Epoch: 29 | 27/31 Batches | Train Loss: 0.1212 |\n| Epoch: 29 | 28/31 Batches | Train Loss: 0.1552 |\n| Epoch: 29 | 29/31 Batches | Train Loss: 0.0839 |\n| Epoch: 29 | 30/31 Batches | Train Loss: 0.1162 |\n| Epoch: 29 | 31/31 Batches | Train Loss: 0.0976 |\n-----------------------------------------------------------\n| Epoch: 29/ 50 | Train Loss: 0.1170 | Val Loss: 1.3763 | Val Accuracy: 0.64 | Time: 72.50s |\nEpoch 29 was ran successfully\nStarting Epoch 30...\n| Epoch: 30 | 1/31 Batches | Train Loss: 0.1290 |\n| Epoch: 30 | 2/31 Batches | Train Loss: 0.1059 |\n| Epoch: 30 | 3/31 Batches | Train Loss: 0.1203 |\n| Epoch: 30 | 4/31 Batches | Train Loss: 0.1272 |\n| Epoch: 30 | 5/31 Batches | Train Loss: 0.1152 |\n| Epoch: 30 | 6/31 Batches | Train Loss: 0.1145 |\n| Epoch: 30 | 7/31 Batches | Train Loss: 0.1389 |\n| Epoch: 30 | 8/31 Batches | Train Loss: 0.0934 |\n| Epoch: 30 | 9/31 Batches | Train Loss: 0.1351 |\n| Epoch: 30 | 10/31 Batches | Train Loss: 0.1306 |\n| Epoch: 30 | 11/31 Batches | Train Loss: 0.0938 |\n| Epoch: 30 | 12/31 Batches | Train Loss: 0.1294 |\n| Epoch: 30 | 13/31 Batches | Train Loss: 0.1047 |\n| Epoch: 30 | 14/31 Batches | Train Loss: 0.1257 |\n| Epoch: 30 | 15/31 Batches | Train Loss: 0.0866 |\n| Epoch: 30 | 16/31 Batches | Train Loss: 0.0732 |\n| Epoch: 30 | 17/31 Batches | Train Loss: 0.0909 |\n| Epoch: 30 | 18/31 Batches | Train Loss: 0.1105 |\n| Epoch: 30 | 19/31 Batches | Train Loss: 0.1055 |\n| Epoch: 30 | 20/31 Batches | Train Loss: 0.1435 |\n| Epoch: 30 | 21/31 Batches | Train Loss: 0.1161 |\n| Epoch: 30 | 22/31 Batches | Train Loss: 0.1026 |\n| Epoch: 30 | 23/31 Batches | Train Loss: 0.0870 |\n| Epoch: 30 | 24/31 Batches | Train Loss: 0.1040 |\n| Epoch: 30 | 25/31 Batches | Train Loss: 0.1080 |\n| Epoch: 30 | 26/31 Batches | Train Loss: 0.1729 |\n| Epoch: 30 | 27/31 Batches | Train Loss: 0.1176 |\n| Epoch: 30 | 28/31 Batches | Train Loss: 0.1000 |\n| Epoch: 30 | 29/31 Batches | Train Loss: 0.1108 |\n| Epoch: 30 | 30/31 Batches | Train Loss: 0.1013 |\n| Epoch: 30 | 31/31 Batches | Train Loss: 0.1447 |\n-----------------------------------------------------------\n| Epoch: 30/ 50 | Train Loss: 0.1142 | Val Loss: 1.4093 | Val Accuracy: 0.63 | Time: 72.43s |\nEpoch 30 was ran successfully\nStarting Epoch 31...\n| Epoch: 31 | 1/31 Batches | Train Loss: 0.1006 |\n| Epoch: 31 | 2/31 Batches | Train Loss: 0.1352 |\n| Epoch: 31 | 3/31 Batches | Train Loss: 0.1001 |\n| Epoch: 31 | 4/31 Batches | Train Loss: 0.0959 |\n| Epoch: 31 | 5/31 Batches | Train Loss: 0.1188 |\n| Epoch: 31 | 6/31 Batches | Train Loss: 0.1088 |\n| Epoch: 31 | 7/31 Batches | Train Loss: 0.1428 |\n| Epoch: 31 | 8/31 Batches | Train Loss: 0.1313 |\n| Epoch: 31 | 9/31 Batches | Train Loss: 0.1082 |\n| Epoch: 31 | 10/31 Batches | Train Loss: 0.1504 |\n| Epoch: 31 | 11/31 Batches | Train Loss: 0.1502 |\n| Epoch: 31 | 12/31 Batches | Train Loss: 0.1148 |\n| Epoch: 31 | 13/31 Batches | Train Loss: 0.1262 |\n| Epoch: 31 | 14/31 Batches | Train Loss: 0.1269 |\n| Epoch: 31 | 15/31 Batches | Train Loss: 0.1058 |\n| Epoch: 31 | 16/31 Batches | Train Loss: 0.1200 |\n| Epoch: 31 | 17/31 Batches | Train Loss: 0.1756 |\n| Epoch: 31 | 18/31 Batches | Train Loss: 0.0918 |\n| Epoch: 31 | 19/31 Batches | Train Loss: 0.1011 |\n| Epoch: 31 | 20/31 Batches | Train Loss: 0.0843 |\n| Epoch: 31 | 21/31 Batches | Train Loss: 0.1307 |\n| Epoch: 31 | 22/31 Batches | Train Loss: 0.0893 |\n| Epoch: 31 | 23/31 Batches | Train Loss: 0.1199 |\n| Epoch: 31 | 24/31 Batches | Train Loss: 0.1185 |\n| Epoch: 31 | 25/31 Batches | Train Loss: 0.0913 |\n| Epoch: 31 | 26/31 Batches | Train Loss: 0.1149 |\n| Epoch: 31 | 27/31 Batches | Train Loss: 0.1264 |\n| Epoch: 31 | 28/31 Batches | Train Loss: 0.0862 |\n| Epoch: 31 | 29/31 Batches | Train Loss: 0.1292 |\n| Epoch: 31 | 30/31 Batches | Train Loss: 0.1035 |\n| Epoch: 31 | 31/31 Batches | Train Loss: 0.1079 |\n-----------------------------------------------------------\n| Epoch: 31/ 50 | Train Loss: 0.1163 | Val Loss: 1.7067 | Val Accuracy: 0.64 | Time: 72.90s |\nEpoch 31 was ran successfully\nStarting Epoch 32...\n| Epoch: 32 | 1/31 Batches | Train Loss: 0.1231 |\n| Epoch: 32 | 2/31 Batches | Train Loss: 0.0864 |\n| Epoch: 32 | 3/31 Batches | Train Loss: 0.1023 |\n| Epoch: 32 | 4/31 Batches | Train Loss: 0.1176 |\n| Epoch: 32 | 5/31 Batches | Train Loss: 0.1153 |\n| Epoch: 32 | 6/31 Batches | Train Loss: 0.1162 |\n| Epoch: 32 | 7/31 Batches | Train Loss: 0.1189 |\n| Epoch: 32 | 8/31 Batches | Train Loss: 0.0946 |\n| Epoch: 32 | 9/31 Batches | Train Loss: 0.1306 |\n| Epoch: 32 | 10/31 Batches | Train Loss: 0.1239 |\n| Epoch: 32 | 11/31 Batches | Train Loss: 0.0898 |\n| Epoch: 32 | 12/31 Batches | Train Loss: 0.1426 |\n| Epoch: 32 | 13/31 Batches | Train Loss: 0.1614 |\n| Epoch: 32 | 14/31 Batches | Train Loss: 0.1468 |\n| Epoch: 32 | 15/31 Batches | Train Loss: 0.1188 |\n| Epoch: 32 | 16/31 Batches | Train Loss: 0.1214 |\n| Epoch: 32 | 17/31 Batches | Train Loss: 0.0791 |\n| Epoch: 32 | 18/31 Batches | Train Loss: 0.1407 |\n| Epoch: 32 | 19/31 Batches | Train Loss: 0.1034 |\n| Epoch: 32 | 20/31 Batches | Train Loss: 0.1279 |\n| Epoch: 32 | 21/31 Batches | Train Loss: 0.1511 |\n| Epoch: 32 | 22/31 Batches | Train Loss: 0.1092 |\n| Epoch: 32 | 23/31 Batches | Train Loss: 0.0985 |\n| Epoch: 32 | 24/31 Batches | Train Loss: 0.1136 |\n| Epoch: 32 | 25/31 Batches | Train Loss: 0.1005 |\n| Epoch: 32 | 26/31 Batches | Train Loss: 0.1163 |\n| Epoch: 32 | 27/31 Batches | Train Loss: 0.1214 |\n| Epoch: 32 | 28/31 Batches | Train Loss: 0.1068 |\n| Epoch: 32 | 29/31 Batches | Train Loss: 0.1048 |\n| Epoch: 32 | 30/31 Batches | Train Loss: 0.1053 |\n| Epoch: 32 | 31/31 Batches | Train Loss: 0.1197 |\n-----------------------------------------------------------\n| Epoch: 32/ 50 | Train Loss: 0.1164 | Val Loss: 1.5785 | Val Accuracy: 0.64 | Time: 72.58s |\nEpoch 32 was ran successfully\nStarting Epoch 33...\n| Epoch: 33 | 1/31 Batches | Train Loss: 0.1200 |\n| Epoch: 33 | 2/31 Batches | Train Loss: 0.1010 |\n| Epoch: 33 | 3/31 Batches | Train Loss: 0.1247 |\n| Epoch: 33 | 4/31 Batches | Train Loss: 0.1422 |\n| Epoch: 33 | 5/31 Batches | Train Loss: 0.1052 |\n| Epoch: 33 | 6/31 Batches | Train Loss: 0.0954 |\n| Epoch: 33 | 7/31 Batches | Train Loss: 0.1072 |\n| Epoch: 33 | 8/31 Batches | Train Loss: 0.0973 |\n| Epoch: 33 | 9/31 Batches | Train Loss: 0.0812 |\n| Epoch: 33 | 10/31 Batches | Train Loss: 0.1132 |\n| Epoch: 33 | 11/31 Batches | Train Loss: 0.1132 |\n| Epoch: 33 | 12/31 Batches | Train Loss: 0.1051 |\n| Epoch: 33 | 13/31 Batches | Train Loss: 0.1101 |\n| Epoch: 33 | 14/31 Batches | Train Loss: 0.1503 |\n| Epoch: 33 | 15/31 Batches | Train Loss: 0.1307 |\n| Epoch: 33 | 16/31 Batches | Train Loss: 0.0947 |\n| Epoch: 33 | 17/31 Batches | Train Loss: 0.1226 |\n| Epoch: 33 | 18/31 Batches | Train Loss: 0.1423 |\n| Epoch: 33 | 19/31 Batches | Train Loss: 0.1000 |\n| Epoch: 33 | 20/31 Batches | Train Loss: 0.0926 |\n| Epoch: 33 | 21/31 Batches | Train Loss: 0.1079 |\n| Epoch: 33 | 22/31 Batches | Train Loss: 0.0757 |\n| Epoch: 33 | 23/31 Batches | Train Loss: 0.1399 |\n| Epoch: 33 | 24/31 Batches | Train Loss: 0.1082 |\n| Epoch: 33 | 25/31 Batches | Train Loss: 0.1323 |\n| Epoch: 33 | 26/31 Batches | Train Loss: 0.1202 |\n| Epoch: 33 | 27/31 Batches | Train Loss: 0.0789 |\n| Epoch: 33 | 28/31 Batches | Train Loss: 0.1444 |\n| Epoch: 33 | 29/31 Batches | Train Loss: 0.1138 |\n| Epoch: 33 | 30/31 Batches | Train Loss: 0.1207 |\n| Epoch: 33 | 31/31 Batches | Train Loss: 0.1049 |\n-----------------------------------------------------------\n| Epoch: 33/ 50 | Train Loss: 0.1128 | Val Loss: 1.2924 | Val Accuracy: 0.65 | Time: 72.23s |\nEpoch 33 was ran successfully\nStarting Epoch 34...\n| Epoch: 34 | 1/31 Batches | Train Loss: 0.1279 |\n| Epoch: 34 | 2/31 Batches | Train Loss: 0.0934 |\n| Epoch: 34 | 3/31 Batches | Train Loss: 0.1079 |\n| Epoch: 34 | 4/31 Batches | Train Loss: 0.1289 |\n| Epoch: 34 | 5/31 Batches | Train Loss: 0.1177 |\n| Epoch: 34 | 6/31 Batches | Train Loss: 0.1071 |\n| Epoch: 34 | 7/31 Batches | Train Loss: 0.0979 |\n| Epoch: 34 | 8/31 Batches | Train Loss: 0.1339 |\n| Epoch: 34 | 9/31 Batches | Train Loss: 0.0889 |\n| Epoch: 34 | 10/31 Batches | Train Loss: 0.1370 |\n| Epoch: 34 | 11/31 Batches | Train Loss: 0.1033 |\n| Epoch: 34 | 12/31 Batches | Train Loss: 0.1167 |\n| Epoch: 34 | 13/31 Batches | Train Loss: 0.1598 |\n| Epoch: 34 | 14/31 Batches | Train Loss: 0.1263 |\n| Epoch: 34 | 15/31 Batches | Train Loss: 0.1432 |\n| Epoch: 34 | 16/31 Batches | Train Loss: 0.1310 |\n| Epoch: 34 | 17/31 Batches | Train Loss: 0.1248 |\n| Epoch: 34 | 18/31 Batches | Train Loss: 0.1202 |\n| Epoch: 34 | 19/31 Batches | Train Loss: 0.1750 |\n| Epoch: 34 | 20/31 Batches | Train Loss: 0.1181 |\n| Epoch: 34 | 21/31 Batches | Train Loss: 0.1412 |\n| Epoch: 34 | 22/31 Batches | Train Loss: 0.1216 |\n| Epoch: 34 | 23/31 Batches | Train Loss: 0.0932 |\n| Epoch: 34 | 24/31 Batches | Train Loss: 0.1191 |\n| Epoch: 34 | 25/31 Batches | Train Loss: 0.1182 |\n| Epoch: 34 | 26/31 Batches | Train Loss: 0.1412 |\n| Epoch: 34 | 27/31 Batches | Train Loss: 0.1233 |\n| Epoch: 34 | 28/31 Batches | Train Loss: 0.1405 |\n| Epoch: 34 | 29/31 Batches | Train Loss: 0.1436 |\n| Epoch: 34 | 30/31 Batches | Train Loss: 0.0993 |\n| Epoch: 34 | 31/31 Batches | Train Loss: 0.1121 |\n-----------------------------------------------------------\n| Epoch: 34/ 50 | Train Loss: 0.1230 | Val Loss: 1.3627 | Val Accuracy: 0.62 | Time: 72.25s |\nEpoch 34 was ran successfully\nStarting Epoch 35...\n| Epoch: 35 | 1/31 Batches | Train Loss: 0.1385 |\n| Epoch: 35 | 2/31 Batches | Train Loss: 0.1046 |\n| Epoch: 35 | 3/31 Batches | Train Loss: 0.0781 |\n| Epoch: 35 | 4/31 Batches | Train Loss: 0.1324 |\n| Epoch: 35 | 5/31 Batches | Train Loss: 0.1106 |\n| Epoch: 35 | 6/31 Batches | Train Loss: 0.1412 |\n| Epoch: 35 | 7/31 Batches | Train Loss: 0.1334 |\n| Epoch: 35 | 8/31 Batches | Train Loss: 0.1086 |\n| Epoch: 35 | 9/31 Batches | Train Loss: 0.0969 |\n| Epoch: 35 | 10/31 Batches | Train Loss: 0.1387 |\n| Epoch: 35 | 11/31 Batches | Train Loss: 0.0952 |\n| Epoch: 35 | 12/31 Batches | Train Loss: 0.1450 |\n| Epoch: 35 | 13/31 Batches | Train Loss: 0.1476 |\n| Epoch: 35 | 14/31 Batches | Train Loss: 0.1127 |\n| Epoch: 35 | 15/31 Batches | Train Loss: 0.1227 |\n| Epoch: 35 | 16/31 Batches | Train Loss: 0.1160 |\n| Epoch: 35 | 17/31 Batches | Train Loss: 0.0787 |\n| Epoch: 35 | 18/31 Batches | Train Loss: 0.1099 |\n| Epoch: 35 | 19/31 Batches | Train Loss: 0.1084 |\n| Epoch: 35 | 20/31 Batches | Train Loss: 0.1094 |\n| Epoch: 35 | 21/31 Batches | Train Loss: 0.0893 |\n| Epoch: 35 | 22/31 Batches | Train Loss: 0.0912 |\n| Epoch: 35 | 23/31 Batches | Train Loss: 0.1067 |\n| Epoch: 35 | 24/31 Batches | Train Loss: 0.1235 |\n| Epoch: 35 | 25/31 Batches | Train Loss: 0.1133 |\n| Epoch: 35 | 26/31 Batches | Train Loss: 0.0898 |\n| Epoch: 35 | 27/31 Batches | Train Loss: 0.1327 |\n| Epoch: 35 | 28/31 Batches | Train Loss: 0.0960 |\n| Epoch: 35 | 29/31 Batches | Train Loss: 0.0999 |\n| Epoch: 35 | 30/31 Batches | Train Loss: 0.1096 |\n| Epoch: 35 | 31/31 Batches | Train Loss: 0.0985 |\n-----------------------------------------------------------\n| Epoch: 35/ 50 | Train Loss: 0.1122 | Val Loss: 1.3530 | Val Accuracy: 0.64 | Time: 71.91s |\nEpoch 35 was ran successfully\nStarting Epoch 36...\n| Epoch: 36 | 1/31 Batches | Train Loss: 0.1134 |\n| Epoch: 36 | 2/31 Batches | Train Loss: 0.0984 |\n| Epoch: 36 | 3/31 Batches | Train Loss: 0.0968 |\n| Epoch: 36 | 4/31 Batches | Train Loss: 0.1200 |\n| Epoch: 36 | 5/31 Batches | Train Loss: 0.1174 |\n| Epoch: 36 | 6/31 Batches | Train Loss: 0.0832 |\n| Epoch: 36 | 7/31 Batches | Train Loss: 0.0623 |\n| Epoch: 36 | 8/31 Batches | Train Loss: 0.0982 |\n| Epoch: 36 | 9/31 Batches | Train Loss: 0.1035 |\n| Epoch: 36 | 10/31 Batches | Train Loss: 0.1069 |\n| Epoch: 36 | 11/31 Batches | Train Loss: 0.0832 |\n| Epoch: 36 | 12/31 Batches | Train Loss: 0.1277 |\n| Epoch: 36 | 13/31 Batches | Train Loss: 0.1191 |\n| Epoch: 36 | 14/31 Batches | Train Loss: 0.0789 |\n| Epoch: 36 | 15/31 Batches | Train Loss: 0.0891 |\n| Epoch: 36 | 16/31 Batches | Train Loss: 0.1210 |\n| Epoch: 36 | 17/31 Batches | Train Loss: 0.1324 |\n| Epoch: 36 | 18/31 Batches | Train Loss: 0.1034 |\n| Epoch: 36 | 19/31 Batches | Train Loss: 0.1043 |\n| Epoch: 36 | 20/31 Batches | Train Loss: 0.1250 |\n| Epoch: 36 | 21/31 Batches | Train Loss: 0.1344 |\n| Epoch: 36 | 22/31 Batches | Train Loss: 0.1216 |\n| Epoch: 36 | 23/31 Batches | Train Loss: 0.0961 |\n| Epoch: 36 | 24/31 Batches | Train Loss: 0.1204 |\n| Epoch: 36 | 25/31 Batches | Train Loss: 0.1057 |\n| Epoch: 36 | 26/31 Batches | Train Loss: 0.0908 |\n| Epoch: 36 | 27/31 Batches | Train Loss: 0.1124 |\n| Epoch: 36 | 28/31 Batches | Train Loss: 0.0810 |\n| Epoch: 36 | 29/31 Batches | Train Loss: 0.1293 |\n| Epoch: 36 | 30/31 Batches | Train Loss: 0.0988 |\n| Epoch: 36 | 31/31 Batches | Train Loss: 0.1041 |\n-----------------------------------------------------------\n| Epoch: 36/ 50 | Train Loss: 0.1058 | Val Loss: 1.3857 | Val Accuracy: 0.64 | Time: 72.91s |\nEpoch 36 was ran successfully\nStarting Epoch 37...\n| Epoch: 37 | 1/31 Batches | Train Loss: 0.0899 |\n| Epoch: 37 | 2/31 Batches | Train Loss: 0.0944 |\n| Epoch: 37 | 3/31 Batches | Train Loss: 0.1146 |\n| Epoch: 37 | 4/31 Batches | Train Loss: 0.1080 |\n| Epoch: 37 | 5/31 Batches | Train Loss: 0.0827 |\n| Epoch: 37 | 6/31 Batches | Train Loss: 0.0900 |\n| Epoch: 37 | 7/31 Batches | Train Loss: 0.1081 |\n| Epoch: 37 | 8/31 Batches | Train Loss: 0.1011 |\n| Epoch: 37 | 9/31 Batches | Train Loss: 0.0890 |\n| Epoch: 37 | 10/31 Batches | Train Loss: 0.1236 |\n| Epoch: 37 | 11/31 Batches | Train Loss: 0.1047 |\n| Epoch: 37 | 12/31 Batches | Train Loss: 0.1067 |\n| Epoch: 37 | 13/31 Batches | Train Loss: 0.0890 |\n| Epoch: 37 | 14/31 Batches | Train Loss: 0.1108 |\n| Epoch: 37 | 15/31 Batches | Train Loss: 0.1219 |\n| Epoch: 37 | 16/31 Batches | Train Loss: 0.1054 |\n| Epoch: 37 | 17/31 Batches | Train Loss: 0.1054 |\n| Epoch: 37 | 18/31 Batches | Train Loss: 0.1079 |\n| Epoch: 37 | 19/31 Batches | Train Loss: 0.1037 |\n| Epoch: 37 | 20/31 Batches | Train Loss: 0.0869 |\n| Epoch: 37 | 21/31 Batches | Train Loss: 0.0959 |\n| Epoch: 37 | 22/31 Batches | Train Loss: 0.0879 |\n| Epoch: 37 | 23/31 Batches | Train Loss: 0.1260 |\n| Epoch: 37 | 24/31 Batches | Train Loss: 0.0815 |\n| Epoch: 37 | 25/31 Batches | Train Loss: 0.0869 |\n| Epoch: 37 | 26/31 Batches | Train Loss: 0.1094 |\n| Epoch: 37 | 27/31 Batches | Train Loss: 0.0885 |\n| Epoch: 37 | 28/31 Batches | Train Loss: 0.1068 |\n| Epoch: 37 | 29/31 Batches | Train Loss: 0.0966 |\n| Epoch: 37 | 30/31 Batches | Train Loss: 0.0944 |\n| Epoch: 37 | 31/31 Batches | Train Loss: 0.0920 |\n-----------------------------------------------------------\n| Epoch: 37/ 50 | Train Loss: 0.1003 | Val Loss: 1.4284 | Val Accuracy: 0.64 | Time: 72.15s |\nEpoch 37 was ran successfully\nStarting Epoch 38...\n| Epoch: 38 | 1/31 Batches | Train Loss: 0.0825 |\n| Epoch: 38 | 2/31 Batches | Train Loss: 0.1032 |\n| Epoch: 38 | 3/31 Batches | Train Loss: 0.0893 |\n| Epoch: 38 | 4/31 Batches | Train Loss: 0.0970 |\n| Epoch: 38 | 5/31 Batches | Train Loss: 0.0841 |\n| Epoch: 38 | 6/31 Batches | Train Loss: 0.1349 |\n| Epoch: 38 | 7/31 Batches | Train Loss: 0.0988 |\n| Epoch: 38 | 8/31 Batches | Train Loss: 0.1082 |\n| Epoch: 38 | 9/31 Batches | Train Loss: 0.0906 |\n| Epoch: 38 | 10/31 Batches | Train Loss: 0.0764 |\n| Epoch: 38 | 11/31 Batches | Train Loss: 0.1025 |\n| Epoch: 38 | 12/31 Batches | Train Loss: 0.1180 |\n| Epoch: 38 | 13/31 Batches | Train Loss: 0.1065 |\n| Epoch: 38 | 14/31 Batches | Train Loss: 0.1122 |\n| Epoch: 38 | 15/31 Batches | Train Loss: 0.1138 |\n| Epoch: 38 | 16/31 Batches | Train Loss: 0.0821 |\n| Epoch: 38 | 17/31 Batches | Train Loss: 0.1076 |\n| Epoch: 38 | 18/31 Batches | Train Loss: 0.0833 |\n| Epoch: 38 | 19/31 Batches | Train Loss: 0.1191 |\n| Epoch: 38 | 20/31 Batches | Train Loss: 0.0800 |\n| Epoch: 38 | 21/31 Batches | Train Loss: 0.1029 |\n| Epoch: 38 | 22/31 Batches | Train Loss: 0.0878 |\n| Epoch: 38 | 23/31 Batches | Train Loss: 0.0757 |\n| Epoch: 38 | 24/31 Batches | Train Loss: 0.1306 |\n| Epoch: 38 | 25/31 Batches | Train Loss: 0.1203 |\n| Epoch: 38 | 26/31 Batches | Train Loss: 0.1209 |\n| Epoch: 38 | 27/31 Batches | Train Loss: 0.0822 |\n| Epoch: 38 | 28/31 Batches | Train Loss: 0.1154 |\n| Epoch: 38 | 29/31 Batches | Train Loss: 0.0887 |\n| Epoch: 38 | 30/31 Batches | Train Loss: 0.1019 |\n| Epoch: 38 | 31/31 Batches | Train Loss: 0.1031 |\n-----------------------------------------------------------\n| Epoch: 38/ 50 | Train Loss: 0.1006 | Val Loss: 1.4637 | Val Accuracy: 0.64 | Time: 72.10s |\nEpoch 38 was ran successfully\nStarting Epoch 39...\n| Epoch: 39 | 1/31 Batches | Train Loss: 0.0795 |\n| Epoch: 39 | 2/31 Batches | Train Loss: 0.1098 |\n| Epoch: 39 | 3/31 Batches | Train Loss: 0.0884 |\n| Epoch: 39 | 4/31 Batches | Train Loss: 0.1095 |\n| Epoch: 39 | 5/31 Batches | Train Loss: 0.1307 |\n| Epoch: 39 | 6/31 Batches | Train Loss: 0.1073 |\n| Epoch: 39 | 7/31 Batches | Train Loss: 0.1227 |\n| Epoch: 39 | 8/31 Batches | Train Loss: 0.0873 |\n| Epoch: 39 | 9/31 Batches | Train Loss: 0.1100 |\n| Epoch: 39 | 10/31 Batches | Train Loss: 0.0950 |\n| Epoch: 39 | 11/31 Batches | Train Loss: 0.1137 |\n| Epoch: 39 | 12/31 Batches | Train Loss: 0.1048 |\n| Epoch: 39 | 13/31 Batches | Train Loss: 0.0945 |\n| Epoch: 39 | 14/31 Batches | Train Loss: 0.1148 |\n| Epoch: 39 | 15/31 Batches | Train Loss: 0.1139 |\n| Epoch: 39 | 16/31 Batches | Train Loss: 0.0942 |\n| Epoch: 39 | 17/31 Batches | Train Loss: 0.0775 |\n| Epoch: 39 | 18/31 Batches | Train Loss: 0.0855 |\n| Epoch: 39 | 19/31 Batches | Train Loss: 0.0903 |\n| Epoch: 39 | 20/31 Batches | Train Loss: 0.0750 |\n| Epoch: 39 | 21/31 Batches | Train Loss: 0.0771 |\n| Epoch: 39 | 22/31 Batches | Train Loss: 0.0899 |\n| Epoch: 39 | 23/31 Batches | Train Loss: 0.1013 |\n| Epoch: 39 | 24/31 Batches | Train Loss: 0.1259 |\n| Epoch: 39 | 25/31 Batches | Train Loss: 0.0906 |\n| Epoch: 39 | 26/31 Batches | Train Loss: 0.1058 |\n| Epoch: 39 | 27/31 Batches | Train Loss: 0.1034 |\n| Epoch: 39 | 28/31 Batches | Train Loss: 0.1005 |\n| Epoch: 39 | 29/31 Batches | Train Loss: 0.1018 |\n| Epoch: 39 | 30/31 Batches | Train Loss: 0.1275 |\n| Epoch: 39 | 31/31 Batches | Train Loss: 0.0709 |\n-----------------------------------------------------------\n| Epoch: 39/ 50 | Train Loss: 0.1000 | Val Loss: 1.4458 | Val Accuracy: 0.64 | Time: 72.21s |\nEpoch 39 was ran successfully\nStarting Epoch 40...\n| Epoch: 40 | 1/31 Batches | Train Loss: 0.0920 |\n| Epoch: 40 | 2/31 Batches | Train Loss: 0.1007 |\n| Epoch: 40 | 3/31 Batches | Train Loss: 0.1273 |\n| Epoch: 40 | 4/31 Batches | Train Loss: 0.0646 |\n| Epoch: 40 | 5/31 Batches | Train Loss: 0.1087 |\n| Epoch: 40 | 6/31 Batches | Train Loss: 0.0965 |\n| Epoch: 40 | 7/31 Batches | Train Loss: 0.0810 |\n| Epoch: 40 | 8/31 Batches | Train Loss: 0.0968 |\n| Epoch: 40 | 9/31 Batches | Train Loss: 0.1027 |\n| Epoch: 40 | 10/31 Batches | Train Loss: 0.0830 |\n| Epoch: 40 | 11/31 Batches | Train Loss: 0.0971 |\n| Epoch: 40 | 12/31 Batches | Train Loss: 0.0885 |\n| Epoch: 40 | 13/31 Batches | Train Loss: 0.1089 |\n| Epoch: 40 | 14/31 Batches | Train Loss: 0.0973 |\n| Epoch: 40 | 15/31 Batches | Train Loss: 0.1388 |\n| Epoch: 40 | 16/31 Batches | Train Loss: 0.0976 |\n| Epoch: 40 | 17/31 Batches | Train Loss: 0.1014 |\n| Epoch: 40 | 18/31 Batches | Train Loss: 0.1025 |\n| Epoch: 40 | 19/31 Batches | Train Loss: 0.1457 |\n| Epoch: 40 | 20/31 Batches | Train Loss: 0.1160 |\n| Epoch: 40 | 21/31 Batches | Train Loss: 0.0912 |\n| Epoch: 40 | 22/31 Batches | Train Loss: 0.1107 |\n| Epoch: 40 | 23/31 Batches | Train Loss: 0.0959 |\n| Epoch: 40 | 24/31 Batches | Train Loss: 0.1026 |\n| Epoch: 40 | 25/31 Batches | Train Loss: 0.0744 |\n| Epoch: 40 | 26/31 Batches | Train Loss: 0.0768 |\n| Epoch: 40 | 27/31 Batches | Train Loss: 0.1037 |\n| Epoch: 40 | 28/31 Batches | Train Loss: 0.1224 |\n| Epoch: 40 | 29/31 Batches | Train Loss: 0.0780 |\n| Epoch: 40 | 30/31 Batches | Train Loss: 0.0997 |\n| Epoch: 40 | 31/31 Batches | Train Loss: 0.0829 |\n-----------------------------------------------------------\n| Epoch: 40/ 50 | Train Loss: 0.0995 | Val Loss: 1.4623 | Val Accuracy: 0.64 | Time: 73.99s |\nEpoch 40 was ran successfully\nStarting Epoch 41...\n| Epoch: 41 | 1/31 Batches | Train Loss: 0.0974 |\n| Epoch: 41 | 2/31 Batches | Train Loss: 0.1160 |\n| Epoch: 41 | 3/31 Batches | Train Loss: 0.1031 |\n| Epoch: 41 | 4/31 Batches | Train Loss: 0.1124 |\n| Epoch: 41 | 5/31 Batches | Train Loss: 0.1133 |\n| Epoch: 41 | 6/31 Batches | Train Loss: 0.0848 |\n| Epoch: 41 | 7/31 Batches | Train Loss: 0.0968 |\n| Epoch: 41 | 8/31 Batches | Train Loss: 0.0972 |\n| Epoch: 41 | 9/31 Batches | Train Loss: 0.0878 |\n| Epoch: 41 | 10/31 Batches | Train Loss: 0.0682 |\n| Epoch: 41 | 11/31 Batches | Train Loss: 0.1005 |\n| Epoch: 41 | 12/31 Batches | Train Loss: 0.1084 |\n| Epoch: 41 | 13/31 Batches | Train Loss: 0.1116 |\n| Epoch: 41 | 14/31 Batches | Train Loss: 0.0696 |\n| Epoch: 41 | 15/31 Batches | Train Loss: 0.1303 |\n| Epoch: 41 | 16/31 Batches | Train Loss: 0.0774 |\n| Epoch: 41 | 17/31 Batches | Train Loss: 0.0895 |\n| Epoch: 41 | 18/31 Batches | Train Loss: 0.0714 |\n| Epoch: 41 | 19/31 Batches | Train Loss: 0.0793 |\n| Epoch: 41 | 20/31 Batches | Train Loss: 0.1099 |\n| Epoch: 41 | 21/31 Batches | Train Loss: 0.0795 |\n| Epoch: 41 | 22/31 Batches | Train Loss: 0.1026 |\n| Epoch: 41 | 23/31 Batches | Train Loss: 0.1020 |\n| Epoch: 41 | 24/31 Batches | Train Loss: 0.1023 |\n| Epoch: 41 | 25/31 Batches | Train Loss: 0.1263 |\n| Epoch: 41 | 26/31 Batches | Train Loss: 0.0900 |\n| Epoch: 41 | 27/31 Batches | Train Loss: 0.1158 |\n| Epoch: 41 | 28/31 Batches | Train Loss: 0.0925 |\n| Epoch: 41 | 29/31 Batches | Train Loss: 0.1007 |\n| Epoch: 41 | 30/31 Batches | Train Loss: 0.1033 |\n| Epoch: 41 | 31/31 Batches | Train Loss: 0.0785 |\n-----------------------------------------------------------\n| Epoch: 41/ 50 | Train Loss: 0.0974 | Val Loss: 1.5001 | Val Accuracy: 0.65 | Time: 72.24s |\nEpoch 41 was ran successfully\nStarting Epoch 42...\n| Epoch: 42 | 1/31 Batches | Train Loss: 0.0855 |\n| Epoch: 42 | 2/31 Batches | Train Loss: 0.1045 |\n| Epoch: 42 | 3/31 Batches | Train Loss: 0.0995 |\n| Epoch: 42 | 4/31 Batches | Train Loss: 0.0627 |\n| Epoch: 42 | 5/31 Batches | Train Loss: 0.0747 |\n| Epoch: 42 | 6/31 Batches | Train Loss: 0.0846 |\n| Epoch: 42 | 7/31 Batches | Train Loss: 0.1129 |\n| Epoch: 42 | 8/31 Batches | Train Loss: 0.0835 |\n| Epoch: 42 | 9/31 Batches | Train Loss: 0.1023 |\n| Epoch: 42 | 10/31 Batches | Train Loss: 0.0954 |\n| Epoch: 42 | 11/31 Batches | Train Loss: 0.0910 |\n| Epoch: 42 | 12/31 Batches | Train Loss: 0.1084 |\n| Epoch: 42 | 13/31 Batches | Train Loss: 0.0850 |\n| Epoch: 42 | 14/31 Batches | Train Loss: 0.1209 |\n| Epoch: 42 | 15/31 Batches | Train Loss: 0.0845 |\n| Epoch: 42 | 16/31 Batches | Train Loss: 0.0958 |\n| Epoch: 42 | 17/31 Batches | Train Loss: 0.0851 |\n| Epoch: 42 | 18/31 Batches | Train Loss: 0.0726 |\n| Epoch: 42 | 19/31 Batches | Train Loss: 0.1145 |\n| Epoch: 42 | 20/31 Batches | Train Loss: 0.0885 |\n| Epoch: 42 | 21/31 Batches | Train Loss: 0.1141 |\n| Epoch: 42 | 22/31 Batches | Train Loss: 0.0998 |\n| Epoch: 42 | 23/31 Batches | Train Loss: 0.1224 |\n| Epoch: 42 | 24/31 Batches | Train Loss: 0.1065 |\n| Epoch: 42 | 25/31 Batches | Train Loss: 0.1127 |\n| Epoch: 42 | 26/31 Batches | Train Loss: 0.0960 |\n| Epoch: 42 | 27/31 Batches | Train Loss: 0.1359 |\n| Epoch: 42 | 28/31 Batches | Train Loss: 0.0964 |\n| Epoch: 42 | 29/31 Batches | Train Loss: 0.0938 |\n| Epoch: 42 | 30/31 Batches | Train Loss: 0.0887 |\n| Epoch: 42 | 31/31 Batches | Train Loss: 0.0981 |\n-----------------------------------------------------------\n| Epoch: 42/ 50 | Train Loss: 0.0973 | Val Loss: 1.5219 | Val Accuracy: 0.65 | Time: 73.28s |\nEpoch 42 was ran successfully\nStarting Epoch 43...\n| Epoch: 43 | 1/31 Batches | Train Loss: 0.1061 |\n| Epoch: 43 | 2/31 Batches | Train Loss: 0.0836 |\n| Epoch: 43 | 3/31 Batches | Train Loss: 0.0983 |\n| Epoch: 43 | 4/31 Batches | Train Loss: 0.1022 |\n| Epoch: 43 | 5/31 Batches | Train Loss: 0.1247 |\n| Epoch: 43 | 6/31 Batches | Train Loss: 0.1152 |\n| Epoch: 43 | 7/31 Batches | Train Loss: 0.0887 |\n| Epoch: 43 | 8/31 Batches | Train Loss: 0.1095 |\n| Epoch: 43 | 9/31 Batches | Train Loss: 0.0815 |\n| Epoch: 43 | 10/31 Batches | Train Loss: 0.1039 |\n| Epoch: 43 | 11/31 Batches | Train Loss: 0.0904 |\n| Epoch: 43 | 12/31 Batches | Train Loss: 0.1053 |\n| Epoch: 43 | 13/31 Batches | Train Loss: 0.0929 |\n| Epoch: 43 | 14/31 Batches | Train Loss: 0.0971 |\n| Epoch: 43 | 15/31 Batches | Train Loss: 0.1032 |\n| Epoch: 43 | 16/31 Batches | Train Loss: 0.0911 |\n| Epoch: 43 | 17/31 Batches | Train Loss: 0.0889 |\n| Epoch: 43 | 18/31 Batches | Train Loss: 0.1093 |\n| Epoch: 43 | 19/31 Batches | Train Loss: 0.0906 |\n| Epoch: 43 | 20/31 Batches | Train Loss: 0.0960 |\n| Epoch: 43 | 21/31 Batches | Train Loss: 0.0982 |\n| Epoch: 43 | 22/31 Batches | Train Loss: 0.0982 |\n| Epoch: 43 | 23/31 Batches | Train Loss: 0.0772 |\n| Epoch: 43 | 24/31 Batches | Train Loss: 0.0730 |\n| Epoch: 43 | 25/31 Batches | Train Loss: 0.0834 |\n| Epoch: 43 | 26/31 Batches | Train Loss: 0.1255 |\n| Epoch: 43 | 27/31 Batches | Train Loss: 0.0989 |\n| Epoch: 43 | 28/31 Batches | Train Loss: 0.1134 |\n| Epoch: 43 | 29/31 Batches | Train Loss: 0.0826 |\n| Epoch: 43 | 30/31 Batches | Train Loss: 0.0883 |\n| Epoch: 43 | 31/31 Batches | Train Loss: 0.0882 |\n-----------------------------------------------------------\n| Epoch: 43/ 50 | Train Loss: 0.0969 | Val Loss: 1.5387 | Val Accuracy: 0.65 | Time: 73.92s |\nEpoch 43 was ran successfully\nStarting Epoch 44...\n| Epoch: 44 | 1/31 Batches | Train Loss: 0.1039 |\n| Epoch: 44 | 2/31 Batches | Train Loss: 0.1247 |\n| Epoch: 44 | 3/31 Batches | Train Loss: 0.0729 |\n| Epoch: 44 | 4/31 Batches | Train Loss: 0.1045 |\n| Epoch: 44 | 5/31 Batches | Train Loss: 0.0973 |\n| Epoch: 44 | 6/31 Batches | Train Loss: 0.0748 |\n| Epoch: 44 | 7/31 Batches | Train Loss: 0.0773 |\n| Epoch: 44 | 8/31 Batches | Train Loss: 0.0993 |\n| Epoch: 44 | 9/31 Batches | Train Loss: 0.1128 |\n| Epoch: 44 | 10/31 Batches | Train Loss: 0.1041 |\n| Epoch: 44 | 11/31 Batches | Train Loss: 0.0851 |\n| Epoch: 44 | 12/31 Batches | Train Loss: 0.0869 |\n| Epoch: 44 | 13/31 Batches | Train Loss: 0.1251 |\n| Epoch: 44 | 14/31 Batches | Train Loss: 0.1119 |\n| Epoch: 44 | 15/31 Batches | Train Loss: 0.0964 |\n| Epoch: 44 | 16/31 Batches | Train Loss: 0.0958 |\n| Epoch: 44 | 17/31 Batches | Train Loss: 0.0831 |\n| Epoch: 44 | 18/31 Batches | Train Loss: 0.0967 |\n| Epoch: 44 | 19/31 Batches | Train Loss: 0.0887 |\n| Epoch: 44 | 20/31 Batches | Train Loss: 0.0846 |\n| Epoch: 44 | 21/31 Batches | Train Loss: 0.0688 |\n| Epoch: 44 | 22/31 Batches | Train Loss: 0.1037 |\n| Epoch: 44 | 23/31 Batches | Train Loss: 0.1073 |\n| Epoch: 44 | 24/31 Batches | Train Loss: 0.0900 |\n| Epoch: 44 | 25/31 Batches | Train Loss: 0.1049 |\n| Epoch: 44 | 26/31 Batches | Train Loss: 0.1043 |\n| Epoch: 44 | 27/31 Batches | Train Loss: 0.1123 |\n| Epoch: 44 | 28/31 Batches | Train Loss: 0.1256 |\n| Epoch: 44 | 29/31 Batches | Train Loss: 0.0971 |\n| Epoch: 44 | 30/31 Batches | Train Loss: 0.1093 |\n| Epoch: 44 | 31/31 Batches | Train Loss: 0.1127 |\n-----------------------------------------------------------\n| Epoch: 44/ 50 | Train Loss: 0.0988 | Val Loss: 1.5547 | Val Accuracy: 0.64 | Time: 74.04s |\nEpoch 44 was ran successfully\nStarting Epoch 45...\n| Epoch: 45 | 1/31 Batches | Train Loss: 0.0607 |\n| Epoch: 45 | 2/31 Batches | Train Loss: 0.0961 |\n| Epoch: 45 | 3/31 Batches | Train Loss: 0.1117 |\n| Epoch: 45 | 4/31 Batches | Train Loss: 0.0836 |\n| Epoch: 45 | 5/31 Batches | Train Loss: 0.1034 |\n| Epoch: 45 | 6/31 Batches | Train Loss: 0.1176 |\n| Epoch: 45 | 7/31 Batches | Train Loss: 0.0998 |\n| Epoch: 45 | 8/31 Batches | Train Loss: 0.1347 |\n| Epoch: 45 | 9/31 Batches | Train Loss: 0.0813 |\n| Epoch: 45 | 10/31 Batches | Train Loss: 0.1012 |\n| Epoch: 45 | 11/31 Batches | Train Loss: 0.0810 |\n| Epoch: 45 | 12/31 Batches | Train Loss: 0.0897 |\n| Epoch: 45 | 13/31 Batches | Train Loss: 0.0992 |\n| Epoch: 45 | 14/31 Batches | Train Loss: 0.1145 |\n| Epoch: 45 | 15/31 Batches | Train Loss: 0.0846 |\n| Epoch: 45 | 16/31 Batches | Train Loss: 0.0917 |\n| Epoch: 45 | 17/31 Batches | Train Loss: 0.0953 |\n| Epoch: 45 | 18/31 Batches | Train Loss: 0.1011 |\n| Epoch: 45 | 19/31 Batches | Train Loss: 0.1027 |\n| Epoch: 45 | 20/31 Batches | Train Loss: 0.0979 |\n| Epoch: 45 | 21/31 Batches | Train Loss: 0.1128 |\n| Epoch: 45 | 22/31 Batches | Train Loss: 0.0934 |\n| Epoch: 45 | 23/31 Batches | Train Loss: 0.0863 |\n| Epoch: 45 | 24/31 Batches | Train Loss: 0.0600 |\n| Epoch: 45 | 25/31 Batches | Train Loss: 0.1101 |\n| Epoch: 45 | 26/31 Batches | Train Loss: 0.1120 |\n| Epoch: 45 | 27/31 Batches | Train Loss: 0.0886 |\n| Epoch: 45 | 28/31 Batches | Train Loss: 0.1180 |\n| Epoch: 45 | 29/31 Batches | Train Loss: 0.0970 |\n| Epoch: 45 | 30/31 Batches | Train Loss: 0.0925 |\n| Epoch: 45 | 31/31 Batches | Train Loss: 0.0970 |\n-----------------------------------------------------------\n| Epoch: 45/ 50 | Train Loss: 0.0973 | Val Loss: 1.5712 | Val Accuracy: 0.64 | Time: 72.12s |\nEpoch 45 was ran successfully\nStarting Epoch 46...\n| Epoch: 46 | 1/31 Batches | Train Loss: 0.0848 |\n| Epoch: 46 | 2/31 Batches | Train Loss: 0.0939 |\n| Epoch: 46 | 3/31 Batches | Train Loss: 0.1017 |\n| Epoch: 46 | 4/31 Batches | Train Loss: 0.1030 |\n| Epoch: 46 | 5/31 Batches | Train Loss: 0.1017 |\n| Epoch: 46 | 6/31 Batches | Train Loss: 0.1009 |\n| Epoch: 46 | 7/31 Batches | Train Loss: 0.0713 |\n| Epoch: 46 | 8/31 Batches | Train Loss: 0.0912 |\n| Epoch: 46 | 9/31 Batches | Train Loss: 0.1167 |\n| Epoch: 46 | 10/31 Batches | Train Loss: 0.0972 |\n| Epoch: 46 | 11/31 Batches | Train Loss: 0.0779 |\n| Epoch: 46 | 12/31 Batches | Train Loss: 0.1037 |\n| Epoch: 46 | 13/31 Batches | Train Loss: 0.0890 |\n| Epoch: 46 | 14/31 Batches | Train Loss: 0.0934 |\n| Epoch: 46 | 15/31 Batches | Train Loss: 0.0896 |\n| Epoch: 46 | 16/31 Batches | Train Loss: 0.1304 |\n| Epoch: 46 | 17/31 Batches | Train Loss: 0.0748 |\n| Epoch: 46 | 18/31 Batches | Train Loss: 0.1031 |\n| Epoch: 46 | 19/31 Batches | Train Loss: 0.0955 |\n| Epoch: 46 | 20/31 Batches | Train Loss: 0.1272 |\n| Epoch: 46 | 21/31 Batches | Train Loss: 0.1336 |\n| Epoch: 46 | 22/31 Batches | Train Loss: 0.0841 |\n| Epoch: 46 | 23/31 Batches | Train Loss: 0.0806 |\n| Epoch: 46 | 24/31 Batches | Train Loss: 0.0912 |\n| Epoch: 46 | 25/31 Batches | Train Loss: 0.1020 |\n| Epoch: 46 | 26/31 Batches | Train Loss: 0.0783 |\n| Epoch: 46 | 27/31 Batches | Train Loss: 0.0992 |\n| Epoch: 46 | 28/31 Batches | Train Loss: 0.1069 |\n| Epoch: 46 | 29/31 Batches | Train Loss: 0.0718 |\n| Epoch: 46 | 30/31 Batches | Train Loss: 0.0950 |\n| Epoch: 46 | 31/31 Batches | Train Loss: 0.1274 |\n-----------------------------------------------------------\n| Epoch: 46/ 50 | Train Loss: 0.0973 | Val Loss: 1.5757 | Val Accuracy: 0.64 | Time: 72.42s |\nEpoch 46 was ran successfully\nStarting Epoch 47...\n| Epoch: 47 | 1/31 Batches | Train Loss: 0.1044 |\n| Epoch: 47 | 2/31 Batches | Train Loss: 0.1026 |\n| Epoch: 47 | 3/31 Batches | Train Loss: 0.0847 |\n| Epoch: 47 | 4/31 Batches | Train Loss: 0.0559 |\n| Epoch: 47 | 5/31 Batches | Train Loss: 0.1151 |\n| Epoch: 47 | 6/31 Batches | Train Loss: 0.1032 |\n| Epoch: 47 | 7/31 Batches | Train Loss: 0.0829 |\n| Epoch: 47 | 8/31 Batches | Train Loss: 0.1164 |\n| Epoch: 47 | 9/31 Batches | Train Loss: 0.1038 |\n| Epoch: 47 | 10/31 Batches | Train Loss: 0.0827 |\n| Epoch: 47 | 11/31 Batches | Train Loss: 0.1012 |\n| Epoch: 47 | 12/31 Batches | Train Loss: 0.0724 |\n| Epoch: 47 | 13/31 Batches | Train Loss: 0.0943 |\n| Epoch: 47 | 14/31 Batches | Train Loss: 0.1250 |\n| Epoch: 47 | 15/31 Batches | Train Loss: 0.1214 |\n| Epoch: 47 | 16/31 Batches | Train Loss: 0.0919 |\n| Epoch: 47 | 17/31 Batches | Train Loss: 0.0666 |\n| Epoch: 47 | 18/31 Batches | Train Loss: 0.0937 |\n| Epoch: 47 | 19/31 Batches | Train Loss: 0.1199 |\n| Epoch: 47 | 20/31 Batches | Train Loss: 0.1075 |\n| Epoch: 47 | 21/31 Batches | Train Loss: 0.0777 |\n| Epoch: 47 | 22/31 Batches | Train Loss: 0.0848 |\n| Epoch: 47 | 23/31 Batches | Train Loss: 0.0773 |\n| Epoch: 47 | 24/31 Batches | Train Loss: 0.0996 |\n| Epoch: 47 | 25/31 Batches | Train Loss: 0.1114 |\n| Epoch: 47 | 26/31 Batches | Train Loss: 0.1030 |\n| Epoch: 47 | 27/31 Batches | Train Loss: 0.1472 |\n| Epoch: 47 | 28/31 Batches | Train Loss: 0.0753 |\n| Epoch: 47 | 29/31 Batches | Train Loss: 0.0980 |\n| Epoch: 47 | 30/31 Batches | Train Loss: 0.1132 |\n| Epoch: 47 | 31/31 Batches | Train Loss: 0.0678 |\n-----------------------------------------------------------\n| Epoch: 47/ 50 | Train Loss: 0.0968 | Val Loss: 1.6025 | Val Accuracy: 0.64 | Time: 73.63s |\nEpoch 47 was ran successfully\nStarting Epoch 48...\n| Epoch: 48 | 1/31 Batches | Train Loss: 0.1074 |\n| Epoch: 48 | 2/31 Batches | Train Loss: 0.1049 |\n| Epoch: 48 | 3/31 Batches | Train Loss: 0.0647 |\n| Epoch: 48 | 4/31 Batches | Train Loss: 0.0929 |\n| Epoch: 48 | 5/31 Batches | Train Loss: 0.1010 |\n| Epoch: 48 | 6/31 Batches | Train Loss: 0.0599 |\n| Epoch: 48 | 7/31 Batches | Train Loss: 0.0997 |\n| Epoch: 48 | 8/31 Batches | Train Loss: 0.1051 |\n| Epoch: 48 | 9/31 Batches | Train Loss: 0.0951 |\n| Epoch: 48 | 10/31 Batches | Train Loss: 0.1211 |\n| Epoch: 48 | 11/31 Batches | Train Loss: 0.1023 |\n| Epoch: 48 | 12/31 Batches | Train Loss: 0.1047 |\n| Epoch: 48 | 13/31 Batches | Train Loss: 0.1023 |\n| Epoch: 48 | 14/31 Batches | Train Loss: 0.0933 |\n| Epoch: 48 | 15/31 Batches | Train Loss: 0.0928 |\n| Epoch: 48 | 16/31 Batches | Train Loss: 0.1049 |\n| Epoch: 48 | 17/31 Batches | Train Loss: 0.1061 |\n| Epoch: 48 | 18/31 Batches | Train Loss: 0.0926 |\n| Epoch: 48 | 19/31 Batches | Train Loss: 0.0837 |\n| Epoch: 48 | 20/31 Batches | Train Loss: 0.1049 |\n| Epoch: 48 | 21/31 Batches | Train Loss: 0.0831 |\n| Epoch: 48 | 22/31 Batches | Train Loss: 0.0894 |\n| Epoch: 48 | 23/31 Batches | Train Loss: 0.1061 |\n| Epoch: 48 | 24/31 Batches | Train Loss: 0.1153 |\n| Epoch: 48 | 25/31 Batches | Train Loss: 0.1038 |\n| Epoch: 48 | 26/31 Batches | Train Loss: 0.0738 |\n| Epoch: 48 | 27/31 Batches | Train Loss: 0.0962 |\n| Epoch: 48 | 28/31 Batches | Train Loss: 0.0939 |\n| Epoch: 48 | 29/31 Batches | Train Loss: 0.0947 |\n| Epoch: 48 | 30/31 Batches | Train Loss: 0.0963 |\n| Epoch: 48 | 31/31 Batches | Train Loss: 0.1033 |\n-----------------------------------------------------------\n| Epoch: 48/ 50 | Train Loss: 0.0966 | Val Loss: 1.6024 | Val Accuracy: 0.64 | Time: 74.99s |\nEpoch 48 was ran successfully\nStarting Epoch 49...\n| Epoch: 49 | 1/31 Batches | Train Loss: 0.1032 |\n| Epoch: 49 | 2/31 Batches | Train Loss: 0.0836 |\n| Epoch: 49 | 3/31 Batches | Train Loss: 0.1176 |\n| Epoch: 49 | 4/31 Batches | Train Loss: 0.0720 |\n| Epoch: 49 | 5/31 Batches | Train Loss: 0.0878 |\n| Epoch: 49 | 6/31 Batches | Train Loss: 0.0892 |\n| Epoch: 49 | 7/31 Batches | Train Loss: 0.0647 |\n| Epoch: 49 | 8/31 Batches | Train Loss: 0.1088 |\n| Epoch: 49 | 9/31 Batches | Train Loss: 0.1127 |\n| Epoch: 49 | 10/31 Batches | Train Loss: 0.1061 |\n| Epoch: 49 | 11/31 Batches | Train Loss: 0.0980 |\n| Epoch: 49 | 12/31 Batches | Train Loss: 0.0881 |\n| Epoch: 49 | 13/31 Batches | Train Loss: 0.0936 |\n| Epoch: 49 | 14/31 Batches | Train Loss: 0.1007 |\n| Epoch: 49 | 15/31 Batches | Train Loss: 0.1383 |\n| Epoch: 49 | 16/31 Batches | Train Loss: 0.0901 |\n| Epoch: 49 | 17/31 Batches | Train Loss: 0.0814 |\n| Epoch: 49 | 18/31 Batches | Train Loss: 0.1049 |\n| Epoch: 49 | 19/31 Batches | Train Loss: 0.0919 |\n| Epoch: 49 | 20/31 Batches | Train Loss: 0.0897 |\n| Epoch: 49 | 21/31 Batches | Train Loss: 0.1002 |\n| Epoch: 49 | 22/31 Batches | Train Loss: 0.0978 |\n| Epoch: 49 | 23/31 Batches | Train Loss: 0.1086 |\n| Epoch: 49 | 24/31 Batches | Train Loss: 0.1048 |\n| Epoch: 49 | 25/31 Batches | Train Loss: 0.0852 |\n| Epoch: 49 | 26/31 Batches | Train Loss: 0.0877 |\n| Epoch: 49 | 27/31 Batches | Train Loss: 0.0804 |\n| Epoch: 49 | 28/31 Batches | Train Loss: 0.1033 |\n| Epoch: 49 | 29/31 Batches | Train Loss: 0.0986 |\n| Epoch: 49 | 30/31 Batches | Train Loss: 0.1046 |\n| Epoch: 49 | 31/31 Batches | Train Loss: 0.0995 |\n-----------------------------------------------------------\n| Epoch: 49/ 50 | Train Loss: 0.0966 | Val Loss: 1.6261 | Val Accuracy: 0.64 | Time: 73.05s |\nEpoch 49 was ran successfully\nStarting Epoch 50...\n| Epoch: 50 | 1/31 Batches | Train Loss: 0.1005 |\n| Epoch: 50 | 2/31 Batches | Train Loss: 0.0972 |\n| Epoch: 50 | 3/31 Batches | Train Loss: 0.1005 |\n| Epoch: 50 | 4/31 Batches | Train Loss: 0.0948 |\n| Epoch: 50 | 5/31 Batches | Train Loss: 0.0714 |\n| Epoch: 50 | 6/31 Batches | Train Loss: 0.0990 |\n| Epoch: 50 | 7/31 Batches | Train Loss: 0.0973 |\n| Epoch: 50 | 8/31 Batches | Train Loss: 0.0819 |\n| Epoch: 50 | 9/31 Batches | Train Loss: 0.0799 |\n| Epoch: 50 | 10/31 Batches | Train Loss: 0.1031 |\n| Epoch: 50 | 11/31 Batches | Train Loss: 0.0818 |\n| Epoch: 50 | 12/31 Batches | Train Loss: 0.0941 |\n| Epoch: 50 | 13/31 Batches | Train Loss: 0.0886 |\n| Epoch: 50 | 14/31 Batches | Train Loss: 0.1089 |\n| Epoch: 50 | 15/31 Batches | Train Loss: 0.1169 |\n| Epoch: 50 | 16/31 Batches | Train Loss: 0.0950 |\n| Epoch: 50 | 17/31 Batches | Train Loss: 0.1108 |\n| Epoch: 50 | 18/31 Batches | Train Loss: 0.1039 |\n| Epoch: 50 | 19/31 Batches | Train Loss: 0.0721 |\n| Epoch: 50 | 20/31 Batches | Train Loss: 0.1266 |\n| Epoch: 50 | 21/31 Batches | Train Loss: 0.0964 |\n| Epoch: 50 | 22/31 Batches | Train Loss: 0.0861 |\n| Epoch: 50 | 23/31 Batches | Train Loss: 0.0786 |\n| Epoch: 50 | 24/31 Batches | Train Loss: 0.1009 |\n| Epoch: 50 | 25/31 Batches | Train Loss: 0.1030 |\n| Epoch: 50 | 26/31 Batches | Train Loss: 0.0989 |\n| Epoch: 50 | 27/31 Batches | Train Loss: 0.1165 |\n| Epoch: 50 | 28/31 Batches | Train Loss: 0.0909 |\n| Epoch: 50 | 29/31 Batches | Train Loss: 0.1099 |\n| Epoch: 50 | 30/31 Batches | Train Loss: 0.0892 |\n| Epoch: 50 | 31/31 Batches | Train Loss: 0.1135 |\n-----------------------------------------------------------\n| Epoch: 50/ 50 | Train Loss: 0.0970 | Val Loss: 1.6602 | Val Accuracy: 0.64 | Time: 72.65s |\nEpoch 50 was ran successfully\nDone!\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"val_loss, val_acc = eval(model,\n                        val_loader,\n                        criterion,\n                        device)\n\ntest_loss, test_acc = eval(\n    model,\n    test_loader,\n    criterion,\n    device\n)\nprint(\"Done!\")","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T10:12:12.207186Z","iopub.execute_input":"2025-01-04T10:12:12.207438Z","iopub.status.idle":"2025-01-04T10:12:26.085767Z","shell.execute_reply.started":"2025-01-04T10:12:12.207416Z","shell.execute_reply":"2025-01-04T10:12:26.084821Z"}},"outputs":[{"name":"stdout","text":"Done!\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"print(f\"Val Accuracy: {val_acc}\")\nprint(f\"Test Accuracy: {test_acc}\")\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T10:12:26.110259Z","iopub.execute_input":"2025-01-04T10:12:26.110481Z","iopub.status.idle":"2025-01-04T10:12:26.124256Z","shell.execute_reply.started":"2025-01-04T10:12:26.110462Z","shell.execute_reply":"2025-01-04T10:12:26.123429Z"}},"outputs":[{"name":"stdout","text":"Val Accuracy: 0.6362704918032787\nTest Accuracy: 0.6572700296735905\nDone!\n","output_type":"stream"}],"execution_count":42}]}